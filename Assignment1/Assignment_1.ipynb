{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to my Github repo: https://github.com/SUN-Wenjun/Advanced_Machine_Learning_Assignment/tree/master/Assignment1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used countries as a categorical variable during our in class mini-hackathon.   This variable actually is categorical at the observation level.  Suffice it to say, in practice we do not really want to build a categorical variable using a variable that has as many categories as it we have observations in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Merge datasets, add region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building your model replace the variable denoting country names with a new variable denoting world regions.  Here is a dataset you can use to merge in this data: https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/worldhappiness2019.csv\")\n",
    "\n",
    "regiondata = pd.read_csv(\"data/region.csv\")\n",
    "\n",
    "\n",
    "mergedata = pd.merge(data, regiondata, how='left', left_on='Country or region', right_on='name')\n",
    "# Check for missing values (there won't be any given that I have already cleaned up the region data)\n",
    "mergedata.loc[pd.isnull(mergedata).iloc[:,9]].to_csv(\"missing.csv\",index=False)\n",
    "\n",
    "# clean up final region data\n",
    "X = mergedata.drop(['Happiness_level', 'name', 'Country or region', 'sub-region'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GDP per capita  Social support  Healthy life expectancy  \\\n",
       "0           1.340           1.587                    0.986   \n",
       "1           1.383           1.573                    0.996   \n",
       "2           1.488           1.582                    1.028   \n",
       "3           1.380           1.624                    1.026   \n",
       "4           1.396           1.522                    0.999   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  region  \n",
       "0                         0.596       0.153                      0.393  Europe  \n",
       "1                         0.592       0.252                      0.410  Europe  \n",
       "2                         0.603       0.271                      0.341  Europe  \n",
       "3                         0.591       0.354                      0.118  Europe  \n",
       "4                         0.557       0.322                      0.298  Europe  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mergedata['Happiness_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore bivariate results (Use visualizations!)\n",
    "\n",
    "Describe any relationships you see between particular features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['GDP per capita','Social support', 'Healthy life expectancy','Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n",
    "for feature in features:\n",
    "    ax = sns.boxplot(x='Happiness_level', y=feature, \n",
    "                     data=mergedata, \n",
    "                     order=['Very Low', 'Low', 'Average', 'High', 'Very High'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Variables that show a positive correlation with happiness level includes: GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices. In other words, as these variables go higher, happiness level goes higher too.\n",
    "\n",
    "Generosity and Perceptions of corruption seem to have no clear correlation with happiness level from the box plots. Although it is interesting to find that countries with 'very high' level of happiness show a slightly higher perceptions of corruption, the varietion of this observation is relatively high. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.crosstab(mergedata['region'], mergedata['Happiness_level'])\n",
    "\n",
    "ax = df.plot.bar()\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.2, 0.8), ncol=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "When it comes to region, most countries in Europe have 'very high' happiness level, while countries in Africa are more in the range of 'very low' and 'low' level of happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine features that predict happiness categories using one or more models that allow for automatic feature selection\n",
    "\n",
    "Explain any meaningful findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features=X.columns.tolist()\n",
    "numeric_features.remove('region')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['region']\n",
    "\n",
    "#Replacing missing values with Modal value and then one hot encoding.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# final preprocessor object set up with ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "#Fit your preprocessor object\n",
    "prediction_input_preprocessor=preprocessor.fit(X_train) \n",
    "\n",
    "import pickle\n",
    "pickle.dump(prediction_input_preprocessor, open( \"preprocessor.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit a random forest model that allow for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 1000))\n",
    "sel.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, SelectFromModel will select the features whose importance is greater than the mean importance of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "According to the result of feature selection, all the region (dummy) variables are considered less important for predicting happiness level than the average level of all the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run at least three prediction models to try to predict World Happiness well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 11)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_input_preprocessor.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 0s 452us/step - loss: 1.6228 - accuracy: 0.1966\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6161 - accuracy: 0.2051\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6095 - accuracy: 0.2564\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6027 - accuracy: 0.2564\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5963 - accuracy: 0.2906\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5895 - accuracy: 0.3077\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5830 - accuracy: 0.3162\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5768 - accuracy: 0.3248\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5705 - accuracy: 0.3419\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5643 - accuracy: 0.3504\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5583 - accuracy: 0.3675\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5524 - accuracy: 0.3932\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5465 - accuracy: 0.4103\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5407 - accuracy: 0.4103\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5347 - accuracy: 0.4444\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5288 - accuracy: 0.4701\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5231 - accuracy: 0.4786\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5168 - accuracy: 0.5043\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5110 - accuracy: 0.4957\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5051 - accuracy: 0.4872\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4996 - accuracy: 0.5043\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4938 - accuracy: 0.4957\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4880 - accuracy: 0.5214\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4824 - accuracy: 0.5214\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4768 - accuracy: 0.5214\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4711 - accuracy: 0.5299\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4654 - accuracy: 0.5299\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4601 - accuracy: 0.5214\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4545 - accuracy: 0.5385\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4488 - accuracy: 0.5385\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4435 - accuracy: 0.5385\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4383 - accuracy: 0.5470\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4330 - accuracy: 0.5470\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4277 - accuracy: 0.5385\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4223 - accuracy: 0.5385\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4171 - accuracy: 0.5385\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4118 - accuracy: 0.5385\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4066 - accuracy: 0.5385\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4014 - accuracy: 0.5385\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3965 - accuracy: 0.5385\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3913 - accuracy: 0.5385\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3861 - accuracy: 0.5385\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3813 - accuracy: 0.5385\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3761 - accuracy: 0.5385\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3711 - accuracy: 0.5470\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3660 - accuracy: 0.5470\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3612 - accuracy: 0.5470\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3562 - accuracy: 0.5470\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3512 - accuracy: 0.5470\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3466 - accuracy: 0.5470\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3415 - accuracy: 0.5470\n",
      "Epoch 52/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3367 - accuracy: 0.5470\n",
      "Epoch 53/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3318 - accuracy: 0.5470\n",
      "Epoch 54/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3271 - accuracy: 0.5556\n",
      "Epoch 55/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3225 - accuracy: 0.5470\n",
      "Epoch 56/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3175 - accuracy: 0.5556\n",
      "Epoch 57/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3130 - accuracy: 0.5556\n",
      "Epoch 58/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3081 - accuracy: 0.5641\n",
      "Epoch 59/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3036 - accuracy: 0.5556\n",
      "Epoch 60/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2987 - accuracy: 0.5556\n",
      "Epoch 61/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2940 - accuracy: 0.5556\n",
      "Epoch 62/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2726 - accuracy: 0.65 - 0s 43us/step - loss: 1.2894 - accuracy: 0.5641\n",
      "Epoch 63/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2848 - accuracy: 0.5641\n",
      "Epoch 64/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2801 - accuracy: 0.5726\n",
      "Epoch 65/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2756 - accuracy: 0.5726\n",
      "Epoch 66/300\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.2709 - accuracy: 0.5812\n",
      "Epoch 67/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2665 - accuracy: 0.5812\n",
      "Epoch 68/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2620 - accuracy: 0.5812\n",
      "Epoch 69/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2574 - accuracy: 0.5812\n",
      "Epoch 70/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2535 - accuracy: 0.5812\n",
      "Epoch 71/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2485 - accuracy: 0.5812\n",
      "Epoch 72/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2442 - accuracy: 0.5812\n",
      "Epoch 73/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2397 - accuracy: 0.5812\n",
      "Epoch 74/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2354 - accuracy: 0.5812\n",
      "Epoch 75/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2310 - accuracy: 0.5812\n",
      "Epoch 76/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2267 - accuracy: 0.5897\n",
      "Epoch 77/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2227 - accuracy: 0.5897\n",
      "Epoch 78/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2182 - accuracy: 0.5897\n",
      "Epoch 79/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2139 - accuracy: 0.5897\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 1.2097 - accuracy: 0.5897\n",
      "Epoch 81/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2056 - accuracy: 0.5897\n",
      "Epoch 82/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2014 - accuracy: 0.5897\n",
      "Epoch 83/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1974 - accuracy: 0.5897\n",
      "Epoch 84/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1935 - accuracy: 0.5897\n",
      "Epoch 85/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1893 - accuracy: 0.5897\n",
      "Epoch 86/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1851 - accuracy: 0.5897\n",
      "Epoch 87/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1811 - accuracy: 0.5897\n",
      "Epoch 88/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1771 - accuracy: 0.5897\n",
      "Epoch 89/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1734 - accuracy: 0.6068\n",
      "Epoch 90/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1697 - accuracy: 0.5983\n",
      "Epoch 91/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1655 - accuracy: 0.5983\n",
      "Epoch 92/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1619 - accuracy: 0.5983\n",
      "Epoch 93/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1579 - accuracy: 0.6068\n",
      "Epoch 94/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1545 - accuracy: 0.5983\n",
      "Epoch 95/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1507 - accuracy: 0.5983\n",
      "Epoch 96/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1470 - accuracy: 0.6068\n",
      "Epoch 97/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1432 - accuracy: 0.6068\n",
      "Epoch 98/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1395 - accuracy: 0.5983\n",
      "Epoch 99/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1359 - accuracy: 0.5983\n",
      "Epoch 100/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1323 - accuracy: 0.5983\n",
      "Epoch 101/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1288 - accuracy: 0.5983\n",
      "Epoch 102/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1255 - accuracy: 0.5983\n",
      "Epoch 103/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1224 - accuracy: 0.5897\n",
      "Epoch 104/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1186 - accuracy: 0.5897\n",
      "Epoch 105/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1154 - accuracy: 0.5897\n",
      "Epoch 106/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1118 - accuracy: 0.5897\n",
      "Epoch 107/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1089 - accuracy: 0.5897\n",
      "Epoch 108/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1053 - accuracy: 0.5897\n",
      "Epoch 109/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1019 - accuracy: 0.5897\n",
      "Epoch 110/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0991 - accuracy: 0.5897\n",
      "Epoch 111/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0959 - accuracy: 0.5897\n",
      "Epoch 112/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0924 - accuracy: 0.5983\n",
      "Epoch 113/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0893 - accuracy: 0.5983\n",
      "Epoch 114/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0860 - accuracy: 0.5983\n",
      "Epoch 115/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0832 - accuracy: 0.5983\n",
      "Epoch 116/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0800 - accuracy: 0.5983\n",
      "Epoch 117/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0769 - accuracy: 0.5983\n",
      "Epoch 118/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0740 - accuracy: 0.5983\n",
      "Epoch 119/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1454 - accuracy: 0.55 - 0s 43us/step - loss: 1.0711 - accuracy: 0.5983\n",
      "Epoch 120/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0681 - accuracy: 0.5983\n",
      "Epoch 121/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0656 - accuracy: 0.5983\n",
      "Epoch 122/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0623 - accuracy: 0.5983\n",
      "Epoch 123/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0594 - accuracy: 0.5983\n",
      "Epoch 124/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0565 - accuracy: 0.5983\n",
      "Epoch 125/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0538 - accuracy: 0.5983\n",
      "Epoch 126/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0509 - accuracy: 0.5983\n",
      "Epoch 127/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0481 - accuracy: 0.5983\n",
      "Epoch 128/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0455 - accuracy: 0.5983\n",
      "Epoch 129/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0427 - accuracy: 0.5983\n",
      "Epoch 130/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0401 - accuracy: 0.5983\n",
      "Epoch 131/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0374 - accuracy: 0.5983\n",
      "Epoch 132/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0347 - accuracy: 0.5983\n",
      "Epoch 133/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0322 - accuracy: 0.5983\n",
      "Epoch 134/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0294 - accuracy: 0.5983\n",
      "Epoch 135/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0268 - accuracy: 0.5983\n",
      "Epoch 136/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0242 - accuracy: 0.5983\n",
      "Epoch 137/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0218 - accuracy: 0.5983\n",
      "Epoch 138/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0193 - accuracy: 0.5983\n",
      "Epoch 139/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0166 - accuracy: 0.5983\n",
      "Epoch 140/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0142 - accuracy: 0.5983\n",
      "Epoch 141/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0115 - accuracy: 0.6068\n",
      "Epoch 142/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0092 - accuracy: 0.6068\n",
      "Epoch 143/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0070 - accuracy: 0.6068\n",
      "Epoch 144/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0042 - accuracy: 0.6068\n",
      "Epoch 145/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0882 - accuracy: 0.51 - 0s 43us/step - loss: 1.0021 - accuracy: 0.6068\n",
      "Epoch 146/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9998 - accuracy: 0.6068\n",
      "Epoch 147/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9972 - accuracy: 0.6068\n",
      "Epoch 148/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9951 - accuracy: 0.6068\n",
      "Epoch 149/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9925 - accuracy: 0.6154\n",
      "Epoch 150/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9902 - accuracy: 0.6154\n",
      "Epoch 151/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9884 - accuracy: 0.6239\n",
      "Epoch 152/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9858 - accuracy: 0.6325\n",
      "Epoch 153/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9832 - accuracy: 0.6325\n",
      "Epoch 154/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9813 - accuracy: 0.6410\n",
      "Epoch 155/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9787 - accuracy: 0.6410\n",
      "Epoch 156/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9770 - accuracy: 0.6581\n",
      "Epoch 157/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9745 - accuracy: 0.6581\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 315us/step - loss: 0.9723 - accuracy: 0.6581\n",
      "Epoch 159/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9700 - accuracy: 0.6581\n",
      "Epoch 160/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9679 - accuracy: 0.6581\n",
      "Epoch 161/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9659 - accuracy: 0.6667\n",
      "Epoch 162/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9637 - accuracy: 0.6581\n",
      "Epoch 163/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9619 - accuracy: 0.6581\n",
      "Epoch 164/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9596 - accuracy: 0.6581\n",
      "Epoch 165/300\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.9577 - accuracy: 0.6581\n",
      "Epoch 166/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9563 - accuracy: 0.6581\n",
      "Epoch 167/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9534 - accuracy: 0.6410\n",
      "Epoch 168/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9515 - accuracy: 0.6496\n",
      "Epoch 169/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9497 - accuracy: 0.6581\n",
      "Epoch 170/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9475 - accuracy: 0.6581\n",
      "Epoch 171/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9458 - accuracy: 0.6581\n",
      "Epoch 172/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9445 - accuracy: 0.6667\n",
      "Epoch 173/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9417 - accuracy: 0.6581\n",
      "Epoch 174/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9399 - accuracy: 0.6581\n",
      "Epoch 175/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9380 - accuracy: 0.6581\n",
      "Epoch 176/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9365 - accuracy: 0.6581\n",
      "Epoch 177/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9343 - accuracy: 0.6581\n",
      "Epoch 178/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9323 - accuracy: 0.6581\n",
      "Epoch 179/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9307 - accuracy: 0.6581\n",
      "Epoch 180/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9287 - accuracy: 0.6581\n",
      "Epoch 181/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9272 - accuracy: 0.6667\n",
      "Epoch 182/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9251 - accuracy: 0.6667\n",
      "Epoch 183/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9232 - accuracy: 0.6752\n",
      "Epoch 184/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9214 - accuracy: 0.6752\n",
      "Epoch 185/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9197 - accuracy: 0.6752\n",
      "Epoch 186/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9187 - accuracy: 0.6752\n",
      "Epoch 187/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9162 - accuracy: 0.6752\n",
      "Epoch 188/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9145 - accuracy: 0.6752\n",
      "Epoch 189/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9128 - accuracy: 0.6752\n",
      "Epoch 190/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9118 - accuracy: 0.6752\n",
      "Epoch 191/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9103 - accuracy: 0.6752\n",
      "Epoch 192/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9080 - accuracy: 0.6752\n",
      "Epoch 193/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9061 - accuracy: 0.6752\n",
      "Epoch 194/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9045 - accuracy: 0.6752\n",
      "Epoch 195/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9031 - accuracy: 0.6752\n",
      "Epoch 196/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9018 - accuracy: 0.6752\n",
      "Epoch 197/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9000 - accuracy: 0.6752\n",
      "Epoch 198/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8983 - accuracy: 0.6752\n",
      "Epoch 199/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8968 - accuracy: 0.6838\n",
      "Epoch 200/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8951 - accuracy: 0.6838\n",
      "Epoch 201/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8937 - accuracy: 0.6838\n",
      "Epoch 202/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8920 - accuracy: 0.6838\n",
      "Epoch 203/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8908 - accuracy: 0.6838\n",
      "Epoch 204/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8890 - accuracy: 0.6838\n",
      "Epoch 205/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8881 - accuracy: 0.6923\n",
      "Epoch 206/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8865 - accuracy: 0.6923\n",
      "Epoch 207/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8848 - accuracy: 0.7009\n",
      "Epoch 208/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8833 - accuracy: 0.6923\n",
      "Epoch 209/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8817 - accuracy: 0.6923\n",
      "Epoch 210/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8801 - accuracy: 0.6923\n",
      "Epoch 211/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8788 - accuracy: 0.6923\n",
      "Epoch 212/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8772 - accuracy: 0.7009\n",
      "Epoch 213/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8762 - accuracy: 0.7009\n",
      "Epoch 214/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8746 - accuracy: 0.6923\n",
      "Epoch 215/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8735 - accuracy: 0.7009\n",
      "Epoch 216/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8718 - accuracy: 0.7009\n",
      "Epoch 217/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8706 - accuracy: 0.7009\n",
      "Epoch 218/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8690 - accuracy: 0.7009\n",
      "Epoch 219/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8679 - accuracy: 0.7009\n",
      "Epoch 220/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8663 - accuracy: 0.7009\n",
      "Epoch 221/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8650 - accuracy: 0.7009\n",
      "Epoch 222/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8634 - accuracy: 0.7009\n",
      "Epoch 223/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8625 - accuracy: 0.7009\n",
      "Epoch 224/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8612 - accuracy: 0.7094\n",
      "Epoch 225/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8595 - accuracy: 0.7009\n",
      "Epoch 226/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8584 - accuracy: 0.7009\n",
      "Epoch 227/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8571 - accuracy: 0.7009\n",
      "Epoch 228/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8556 - accuracy: 0.7009\n",
      "Epoch 229/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8547 - accuracy: 0.7094\n",
      "Epoch 230/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8534 - accuracy: 0.7094\n",
      "Epoch 231/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8022 - accuracy: 0.71 - 0s 51us/step - loss: 0.8518 - accuracy: 0.7094\n",
      "Epoch 232/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8509 - accuracy: 0.7094\n",
      "Epoch 233/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8493 - accuracy: 0.7094\n",
      "Epoch 234/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8485 - accuracy: 0.7094\n",
      "Epoch 235/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8471 - accuracy: 0.7094\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 43us/step - loss: 0.8458 - accuracy: 0.7094\n",
      "Epoch 237/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8450 - accuracy: 0.7094\n",
      "Epoch 238/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8440 - accuracy: 0.7094\n",
      "Epoch 239/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8428 - accuracy: 0.7265\n",
      "Epoch 240/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9184 - accuracy: 0.65 - 0s 43us/step - loss: 0.8411 - accuracy: 0.7179\n",
      "Epoch 241/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8398 - accuracy: 0.7179\n",
      "Epoch 242/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8385 - accuracy: 0.7179\n",
      "Epoch 243/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8376 - accuracy: 0.7265\n",
      "Epoch 244/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8362 - accuracy: 0.7265\n",
      "Epoch 245/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8354 - accuracy: 0.7265\n",
      "Epoch 246/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8342 - accuracy: 0.7265\n",
      "Epoch 247/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8331 - accuracy: 0.7265\n",
      "Epoch 248/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8317 - accuracy: 0.7265\n",
      "Epoch 249/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8312 - accuracy: 0.7265\n",
      "Epoch 250/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8295 - accuracy: 0.7265\n",
      "Epoch 251/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8285 - accuracy: 0.7265\n",
      "Epoch 252/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8275 - accuracy: 0.7265\n",
      "Epoch 253/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8263 - accuracy: 0.7265\n",
      "Epoch 254/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8253 - accuracy: 0.7179\n",
      "Epoch 255/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8241 - accuracy: 0.7265\n",
      "Epoch 256/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8231 - accuracy: 0.7265\n",
      "Epoch 257/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8222 - accuracy: 0.7265\n",
      "Epoch 258/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8210 - accuracy: 0.7265\n",
      "Epoch 259/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8198 - accuracy: 0.7265\n",
      "Epoch 260/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8191 - accuracy: 0.7265\n",
      "Epoch 261/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8178 - accuracy: 0.7265\n",
      "Epoch 262/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8167 - accuracy: 0.7179\n",
      "Epoch 263/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8161 - accuracy: 0.7265\n",
      "Epoch 264/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8148 - accuracy: 0.7179\n",
      "Epoch 265/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8138 - accuracy: 0.7179\n",
      "Epoch 266/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8128 - accuracy: 0.7179\n",
      "Epoch 267/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8121 - accuracy: 0.7179\n",
      "Epoch 268/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8112 - accuracy: 0.7179\n",
      "Epoch 269/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8094 - accuracy: 0.7179\n",
      "Epoch 270/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8085 - accuracy: 0.7179\n",
      "Epoch 271/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8087 - accuracy: 0.7179\n",
      "Epoch 272/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8066 - accuracy: 0.7179\n",
      "Epoch 273/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8061 - accuracy: 0.7179\n",
      "Epoch 274/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8052 - accuracy: 0.7179\n",
      "Epoch 275/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8037 - accuracy: 0.7179\n",
      "Epoch 276/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8031 - accuracy: 0.7179\n",
      "Epoch 277/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8020 - accuracy: 0.7179\n",
      "Epoch 278/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8009 - accuracy: 0.7179\n",
      "Epoch 279/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8012 - accuracy: 0.7265\n",
      "Epoch 280/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.7992 - accuracy: 0.7179\n",
      "Epoch 281/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.7980 - accuracy: 0.7179\n",
      "Epoch 282/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.7980 - accuracy: 0.7179\n",
      "Epoch 283/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7964 - accuracy: 0.7179\n",
      "Epoch 284/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7958 - accuracy: 0.7179\n",
      "Epoch 285/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.7947 - accuracy: 0.7179\n",
      "Epoch 286/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7940 - accuracy: 0.7179\n",
      "Epoch 287/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7933 - accuracy: 0.7179\n",
      "Epoch 288/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.7919 - accuracy: 0.7179\n",
      "Epoch 289/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7910 - accuracy: 0.7179\n",
      "Epoch 290/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7911 - accuracy: 0.7179\n",
      "Epoch 291/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.7902 - accuracy: 0.7179\n",
      "Epoch 292/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7887 - accuracy: 0.7179\n",
      "Epoch 293/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.7873 - accuracy: 0.7179\n",
      "Epoch 294/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7868 - accuracy: 0.7179\n",
      "Epoch 295/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7859 - accuracy: 0.7179\n",
      "Epoch 296/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7854 - accuracy: 0.7179\n",
      "Epoch 297/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7848 - accuracy: 0.7179\n",
      "Epoch 298/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.7831 - accuracy: 0.7179\n",
      "Epoch 299/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.7826 - accuracy: 0.7179\n",
      "Epoch 300/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.7813 - accuracy: 0.7265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20d22aea438>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(124, input_dim=11, activation='relu'))\n",
    "model.add(Dense(124, activation='relu'))\n",
    "model.add(Dense(124, activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.434398</td>\n",
       "      <td>0.44733</td>\n",
       "      <td>0.488571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.435897  0.434398    0.44733  0.488571    0     0    0   0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "def model_eval_metrics(y_true, y_pred,classification=\"TRUE\"):\n",
    "     if classification==\"TRUE\":\n",
    "        accuracy_eval = accuracy_score(y_true, y_pred)\n",
    "        f1_score_eval = f1_score(y_true, y_pred,average=\"macro\")\n",
    "        precision_eval = precision_score(y_true, y_pred,average=\"macro\")\n",
    "        recall_eval = recall_score(y_true, y_pred,average=\"macro\")\n",
    "        mse_eval = 0\n",
    "        rmse_eval = 0\n",
    "        mae_eval = 0\n",
    "        r2_eval = 0\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     else:\n",
    "        accuracy_eval = 0\n",
    "        f1_score_eval = 0\n",
    "        precision_eval = 0\n",
    "        recall_eval = 0\n",
    "        mse_eval = mean_squared_error(y_true, y_pred)\n",
    "        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae_eval = mean_absolute_error(y_true, y_pred)\n",
    "        r2_eval = r2_score(y_true, y_pred)\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     return finalmetricdata\n",
    "\n",
    "modelevalobject = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 0s 435us/step - loss: 1.6635 - accuracy: 0.1538\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6567 - accuracy: 0.1624\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6502 - accuracy: 0.1709\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6437 - accuracy: 0.1795\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6372 - accuracy: 0.1795\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6309 - accuracy: 0.1795\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6252 - accuracy: 0.1795\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6187 - accuracy: 0.1709\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6128 - accuracy: 0.1966\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6067 - accuracy: 0.1966\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.6008 - accuracy: 0.2137\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.5952 - accuracy: 0.2308\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.5894 - accuracy: 0.2308\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5836 - accuracy: 0.2564\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5782 - accuracy: 0.2564\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5727 - accuracy: 0.2650\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5674 - accuracy: 0.2735\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5624 - accuracy: 0.2821\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5567 - accuracy: 0.2991\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5515 - accuracy: 0.3077\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5466 - accuracy: 0.3162\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5415 - accuracy: 0.3333\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5364 - accuracy: 0.3504\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5317 - accuracy: 0.3419\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5273 - accuracy: 0.3419\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5221 - accuracy: 0.3419\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5172 - accuracy: 0.3675\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5125 - accuracy: 0.3846\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5077 - accuracy: 0.4103\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5030 - accuracy: 0.4274\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4982 - accuracy: 0.4444\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4937 - accuracy: 0.4444\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4886 - accuracy: 0.4530\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4840 - accuracy: 0.4615\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4798 - accuracy: 0.4615\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4746 - accuracy: 0.4615\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4700 - accuracy: 0.4786\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4653 - accuracy: 0.4872\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4606 - accuracy: 0.4872\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4564 - accuracy: 0.4872\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4513 - accuracy: 0.4872\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4468 - accuracy: 0.4872\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4421 - accuracy: 0.4786\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4375 - accuracy: 0.4872\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4327 - accuracy: 0.4872\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.4280 - accuracy: 0.4786\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4233 - accuracy: 0.4786\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4187 - accuracy: 0.4786\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4142 - accuracy: 0.4786\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4096 - accuracy: 0.4786\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.4048 - accuracy: 0.4701\n",
      "Epoch 52/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4000 - accuracy: 0.4701\n",
      "Epoch 53/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3955 - accuracy: 0.4701\n",
      "Epoch 54/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3906 - accuracy: 0.4701\n",
      "Epoch 55/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3861 - accuracy: 0.4872\n",
      "Epoch 56/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3813 - accuracy: 0.4957\n",
      "Epoch 57/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3768 - accuracy: 0.4957\n",
      "Epoch 58/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3721 - accuracy: 0.4957\n",
      "Epoch 59/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3673 - accuracy: 0.4957\n",
      "Epoch 60/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3628 - accuracy: 0.4957\n",
      "Epoch 61/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3582 - accuracy: 0.4957\n",
      "Epoch 62/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3535 - accuracy: 0.4957\n",
      "Epoch 63/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3491 - accuracy: 0.4957\n",
      "Epoch 64/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3444 - accuracy: 0.4957\n",
      "Epoch 65/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3398 - accuracy: 0.4957\n",
      "Epoch 66/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3353 - accuracy: 0.4957\n",
      "Epoch 67/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3307 - accuracy: 0.4957\n",
      "Epoch 68/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3263 - accuracy: 0.4957\n",
      "Epoch 69/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3218 - accuracy: 0.4957\n",
      "Epoch 70/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3173 - accuracy: 0.4957\n",
      "Epoch 71/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3130 - accuracy: 0.4957\n",
      "Epoch 72/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3084 - accuracy: 0.4957\n",
      "Epoch 73/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3040 - accuracy: 0.4957\n",
      "Epoch 74/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2996 - accuracy: 0.4957\n",
      "Epoch 75/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2956 - accuracy: 0.4957\n",
      "Epoch 76/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2910 - accuracy: 0.4957\n",
      "Epoch 77/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2868 - accuracy: 0.4957\n",
      "Epoch 78/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2825 - accuracy: 0.4957\n",
      "Epoch 79/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2782 - accuracy: 0.4957\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 1.2740 - accuracy: 0.4957\n",
      "Epoch 81/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2700 - accuracy: 0.5043\n",
      "Epoch 82/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2658 - accuracy: 0.5043\n",
      "Epoch 83/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2619 - accuracy: 0.5043\n",
      "Epoch 84/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2577 - accuracy: 0.5043\n",
      "Epoch 85/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2538 - accuracy: 0.4957\n",
      "Epoch 86/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2497 - accuracy: 0.4957\n",
      "Epoch 87/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2460 - accuracy: 0.4957\n",
      "Epoch 88/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2421 - accuracy: 0.4957\n",
      "Epoch 89/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2384 - accuracy: 0.4957\n",
      "Epoch 90/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2345 - accuracy: 0.4957\n",
      "Epoch 91/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2309 - accuracy: 0.4957\n",
      "Epoch 92/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2273 - accuracy: 0.4957\n",
      "Epoch 93/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2235 - accuracy: 0.5043\n",
      "Epoch 94/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2198 - accuracy: 0.5043\n",
      "Epoch 95/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2163 - accuracy: 0.5043\n",
      "Epoch 96/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2129 - accuracy: 0.5043\n",
      "Epoch 97/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2090 - accuracy: 0.5043\n",
      "Epoch 98/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2056 - accuracy: 0.5128\n",
      "Epoch 99/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2022 - accuracy: 0.5128\n",
      "Epoch 100/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1987 - accuracy: 0.5128\n",
      "Epoch 101/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1954 - accuracy: 0.5128\n",
      "Epoch 102/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1922 - accuracy: 0.5128\n",
      "Epoch 103/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1889 - accuracy: 0.5128\n",
      "Epoch 104/300\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.1855 - accuracy: 0.5128\n",
      "Epoch 105/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1820 - accuracy: 0.5128\n",
      "Epoch 106/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1788 - accuracy: 0.5128\n",
      "Epoch 107/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1758 - accuracy: 0.5128\n",
      "Epoch 108/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1726 - accuracy: 0.5128\n",
      "Epoch 109/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1694 - accuracy: 0.5128\n",
      "Epoch 110/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1664 - accuracy: 0.5128\n",
      "Epoch 111/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1634 - accuracy: 0.5128\n",
      "Epoch 112/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1601 - accuracy: 0.5128\n",
      "Epoch 113/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1573 - accuracy: 0.5128\n",
      "Epoch 114/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1543 - accuracy: 0.5128\n",
      "Epoch 115/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1512 - accuracy: 0.5128\n",
      "Epoch 116/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1483 - accuracy: 0.5128\n",
      "Epoch 117/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1456 - accuracy: 0.5128\n",
      "Epoch 118/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1427 - accuracy: 0.5128\n",
      "Epoch 119/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1397 - accuracy: 0.5128\n",
      "Epoch 120/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1371 - accuracy: 0.5128\n",
      "Epoch 121/300\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.1343 - accuracy: 0.5128\n",
      "Epoch 122/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1319 - accuracy: 0.5214\n",
      "Epoch 123/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1289 - accuracy: 0.5214\n",
      "Epoch 124/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1263 - accuracy: 0.5214\n",
      "Epoch 125/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1234 - accuracy: 0.5214\n",
      "Epoch 126/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1211 - accuracy: 0.5299\n",
      "Epoch 127/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1181 - accuracy: 0.5385\n",
      "Epoch 128/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1157 - accuracy: 0.5385\n",
      "Epoch 129/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1130 - accuracy: 0.5385\n",
      "Epoch 130/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1106 - accuracy: 0.5385\n",
      "Epoch 131/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1079 - accuracy: 0.5385\n",
      "Epoch 132/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1054 - accuracy: 0.5385\n",
      "Epoch 133/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1028 - accuracy: 0.5385\n",
      "Epoch 134/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1008 - accuracy: 0.5385\n",
      "Epoch 135/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0979 - accuracy: 0.5470\n",
      "Epoch 136/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0956 - accuracy: 0.5470\n",
      "Epoch 137/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0929 - accuracy: 0.5470\n",
      "Epoch 138/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0905 - accuracy: 0.5470\n",
      "Epoch 139/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0883 - accuracy: 0.5470\n",
      "Epoch 140/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0859 - accuracy: 0.5470\n",
      "Epoch 141/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0837 - accuracy: 0.5385\n",
      "Epoch 142/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0813 - accuracy: 0.5385\n",
      "Epoch 143/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0789 - accuracy: 0.5385\n",
      "Epoch 144/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0768 - accuracy: 0.5385\n",
      "Epoch 145/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0744 - accuracy: 0.5385\n",
      "Epoch 146/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0722 - accuracy: 0.5470\n",
      "Epoch 147/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0701 - accuracy: 0.5470\n",
      "Epoch 148/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0683 - accuracy: 0.5470\n",
      "Epoch 149/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0658 - accuracy: 0.5470\n",
      "Epoch 150/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0637 - accuracy: 0.5556\n",
      "Epoch 151/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0614 - accuracy: 0.5556\n",
      "Epoch 152/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0595 - accuracy: 0.5470\n",
      "Epoch 153/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0582 - accuracy: 0.5556\n",
      "Epoch 154/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0554 - accuracy: 0.5470\n",
      "Epoch 155/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0535 - accuracy: 0.5470\n",
      "Epoch 156/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0513 - accuracy: 0.5556\n",
      "Epoch 157/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0490 - accuracy: 0.5556\n",
      "Epoch 158/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0474 - accuracy: 0.5556\n",
      "Epoch 159/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 1.0451 - accuracy: 0.5556\n",
      "Epoch 160/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0431 - accuracy: 0.5556\n",
      "Epoch 161/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0414 - accuracy: 0.5470\n",
      "Epoch 162/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0397 - accuracy: 0.5470\n",
      "Epoch 163/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0377 - accuracy: 0.5556\n",
      "Epoch 164/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0355 - accuracy: 0.5470\n",
      "Epoch 165/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0335 - accuracy: 0.5470\n",
      "Epoch 166/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0317 - accuracy: 0.5470\n",
      "Epoch 167/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0297 - accuracy: 0.5385\n",
      "Epoch 168/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0277 - accuracy: 0.5385\n",
      "Epoch 169/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0260 - accuracy: 0.5385\n",
      "Epoch 170/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0242 - accuracy: 0.5385\n",
      "Epoch 171/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0224 - accuracy: 0.5385\n",
      "Epoch 172/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0204 - accuracy: 0.5385\n",
      "Epoch 173/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0186 - accuracy: 0.5385\n",
      "Epoch 174/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0169 - accuracy: 0.5385\n",
      "Epoch 175/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0150 - accuracy: 0.5385\n",
      "Epoch 176/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0133 - accuracy: 0.5385\n",
      "Epoch 177/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0114 - accuracy: 0.5385\n",
      "Epoch 178/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0099 - accuracy: 0.5385\n",
      "Epoch 179/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0078 - accuracy: 0.5385\n",
      "Epoch 180/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0064 - accuracy: 0.5385\n",
      "Epoch 181/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0042 - accuracy: 0.5385\n",
      "Epoch 182/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0027 - accuracy: 0.5385\n",
      "Epoch 183/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0009 - accuracy: 0.5299\n",
      "Epoch 184/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9998 - accuracy: 0.5299\n",
      "Epoch 185/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9976 - accuracy: 0.5299\n",
      "Epoch 186/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9959 - accuracy: 0.5299\n",
      "Epoch 187/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9942 - accuracy: 0.5385\n",
      "Epoch 188/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9927 - accuracy: 0.5385\n",
      "Epoch 189/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9910 - accuracy: 0.5385\n",
      "Epoch 190/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9892 - accuracy: 0.5385\n",
      "Epoch 191/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9878 - accuracy: 0.5385\n",
      "Epoch 192/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9862 - accuracy: 0.5385\n",
      "Epoch 193/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9843 - accuracy: 0.5470\n",
      "Epoch 194/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9830 - accuracy: 0.5385\n",
      "Epoch 195/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9814 - accuracy: 0.5470\n",
      "Epoch 196/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9797 - accuracy: 0.5470\n",
      "Epoch 197/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9786 - accuracy: 0.5470\n",
      "Epoch 198/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9765 - accuracy: 0.5470\n",
      "Epoch 199/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9751 - accuracy: 0.5556\n",
      "Epoch 200/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9739 - accuracy: 0.5470\n",
      "Epoch 201/300\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9723 - accuracy: 0.5470\n",
      "Epoch 202/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9708 - accuracy: 0.5641\n",
      "Epoch 203/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9688 - accuracy: 0.5641\n",
      "Epoch 204/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9673 - accuracy: 0.5812\n",
      "Epoch 205/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9663 - accuracy: 0.5812\n",
      "Epoch 206/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9645 - accuracy: 0.5897\n",
      "Epoch 207/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9634 - accuracy: 0.5897\n",
      "Epoch 208/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9616 - accuracy: 0.5897\n",
      "Epoch 209/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9606 - accuracy: 0.5897\n",
      "Epoch 210/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9588 - accuracy: 0.5897\n",
      "Epoch 211/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9573 - accuracy: 0.5897\n",
      "Epoch 212/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9563 - accuracy: 0.5897\n",
      "Epoch 213/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9546 - accuracy: 0.5897\n",
      "Epoch 214/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9530 - accuracy: 0.5812\n",
      "Epoch 215/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9517 - accuracy: 0.5897\n",
      "Epoch 216/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9503 - accuracy: 0.5897\n",
      "Epoch 217/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9488 - accuracy: 0.5897\n",
      "Epoch 218/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9476 - accuracy: 0.6068\n",
      "Epoch 219/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9463 - accuracy: 0.5983\n",
      "Epoch 220/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9448 - accuracy: 0.5983\n",
      "Epoch 221/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9436 - accuracy: 0.6068\n",
      "Epoch 222/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9423 - accuracy: 0.6068\n",
      "Epoch 223/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9410 - accuracy: 0.6068\n",
      "Epoch 224/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9409 - accuracy: 0.6154\n",
      "Epoch 225/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9382 - accuracy: 0.6154\n",
      "Epoch 226/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9371 - accuracy: 0.6239\n",
      "Epoch 227/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9360 - accuracy: 0.6239\n",
      "Epoch 228/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9344 - accuracy: 0.6239\n",
      "Epoch 229/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9330 - accuracy: 0.6239\n",
      "Epoch 230/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9317 - accuracy: 0.6239\n",
      "Epoch 231/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9304 - accuracy: 0.6239\n",
      "Epoch 232/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9292 - accuracy: 0.6239\n",
      "Epoch 233/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9279 - accuracy: 0.6239\n",
      "Epoch 234/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9267 - accuracy: 0.6239\n",
      "Epoch 235/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9261 - accuracy: 0.6239\n",
      "Epoch 236/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9240 - accuracy: 0.6410\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 0.9233 - accuracy: 0.6325\n",
      "Epoch 238/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9219 - accuracy: 0.6410\n",
      "Epoch 239/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9206 - accuracy: 0.6410\n",
      "Epoch 240/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9194 - accuracy: 0.6325\n",
      "Epoch 241/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9184 - accuracy: 0.6410\n",
      "Epoch 242/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9171 - accuracy: 0.6325\n",
      "Epoch 243/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9157 - accuracy: 0.6410\n",
      "Epoch 244/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9144 - accuracy: 0.6410\n",
      "Epoch 245/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9136 - accuracy: 0.6325\n",
      "Epoch 246/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9123 - accuracy: 0.6325\n",
      "Epoch 247/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9114 - accuracy: 0.6325\n",
      "Epoch 248/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9098 - accuracy: 0.6325\n",
      "Epoch 249/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9088 - accuracy: 0.6239\n",
      "Epoch 250/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9075 - accuracy: 0.6325\n",
      "Epoch 251/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9067 - accuracy: 0.6325\n",
      "Epoch 252/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9051 - accuracy: 0.6325\n",
      "Epoch 253/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9041 - accuracy: 0.6239\n",
      "Epoch 254/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9031 - accuracy: 0.6325\n",
      "Epoch 255/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9017 - accuracy: 0.6239\n",
      "Epoch 256/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9007 - accuracy: 0.6239\n",
      "Epoch 257/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8994 - accuracy: 0.6239\n",
      "Epoch 258/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8985 - accuracy: 0.6239\n",
      "Epoch 259/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8972 - accuracy: 0.6239\n",
      "Epoch 260/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8965 - accuracy: 0.6154\n",
      "Epoch 261/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8953 - accuracy: 0.6154\n",
      "Epoch 262/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8940 - accuracy: 0.6239\n",
      "Epoch 263/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8928 - accuracy: 0.6239\n",
      "Epoch 264/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8926 - accuracy: 0.6239\n",
      "Epoch 265/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8919 - accuracy: 0.6325\n",
      "Epoch 266/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8908 - accuracy: 0.6325\n",
      "Epoch 267/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8887 - accuracy: 0.6325\n",
      "Epoch 268/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8877 - accuracy: 0.6325\n",
      "Epoch 269/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8870 - accuracy: 0.6410\n",
      "Epoch 270/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8863 - accuracy: 0.6325\n",
      "Epoch 271/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8847 - accuracy: 0.6410\n",
      "Epoch 272/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8847 - accuracy: 0.6410\n",
      "Epoch 273/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8831 - accuracy: 0.6496\n",
      "Epoch 274/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8818 - accuracy: 0.6496\n",
      "Epoch 275/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8807 - accuracy: 0.6581\n",
      "Epoch 276/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8812 - accuracy: 0.6581\n",
      "Epoch 277/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8789 - accuracy: 0.6581\n",
      "Epoch 278/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8778 - accuracy: 0.6581\n",
      "Epoch 279/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8770 - accuracy: 0.6667\n",
      "Epoch 280/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8761 - accuracy: 0.6581\n",
      "Epoch 281/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8754 - accuracy: 0.6581\n",
      "Epoch 282/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8743 - accuracy: 0.6581\n",
      "Epoch 283/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8732 - accuracy: 0.6581\n",
      "Epoch 284/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8724 - accuracy: 0.6581\n",
      "Epoch 285/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8718 - accuracy: 0.6581\n",
      "Epoch 286/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8704 - accuracy: 0.6581\n",
      "Epoch 287/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8701 - accuracy: 0.6581\n",
      "Epoch 288/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8693 - accuracy: 0.6581\n",
      "Epoch 289/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8685 - accuracy: 0.6581\n",
      "Epoch 290/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8672 - accuracy: 0.6581\n",
      "Epoch 291/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8661 - accuracy: 0.6581\n",
      "Epoch 292/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8654 - accuracy: 0.6581\n",
      "Epoch 293/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8642 - accuracy: 0.6581\n",
      "Epoch 294/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8636 - accuracy: 0.6581\n",
      "Epoch 295/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8625 - accuracy: 0.6581\n",
      "Epoch 296/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8618 - accuracy: 0.6581\n",
      "Epoch 297/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8612 - accuracy: 0.6581\n",
      "Epoch 298/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8602 - accuracy: 0.6581\n",
      "Epoch 299/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8593 - accuracy: 0.6581\n",
      "Epoch 300/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8584 - accuracy: 0.6581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20d22aea908>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=11, activation='relu')) # change dense to 32\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.439635</td>\n",
       "      <td>0.439286</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision  recall  mse  rmse  mae  r2\n",
       "0  0.461538  0.439635   0.439286    0.48    0     0    0   0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelevalobject = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 0s 366us/step - loss: 1.4942 - accuracy: 0.3590\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4860 - accuracy: 0.3761\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4781 - accuracy: 0.3846\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4698 - accuracy: 0.3846\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4618 - accuracy: 0.3846\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4541 - accuracy: 0.3932\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4466 - accuracy: 0.3846\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4387 - accuracy: 0.4103\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4316 - accuracy: 0.4274\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4243 - accuracy: 0.4274\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4174 - accuracy: 0.4188\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.4106 - accuracy: 0.4188\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4036 - accuracy: 0.4444\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.3970 - accuracy: 0.4530\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3905 - accuracy: 0.4530\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3841 - accuracy: 0.4530\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3777 - accuracy: 0.4444\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3713 - accuracy: 0.4444\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3649 - accuracy: 0.4530\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3588 - accuracy: 0.4530\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3526 - accuracy: 0.4530\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3466 - accuracy: 0.4786\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3409 - accuracy: 0.4786\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3350 - accuracy: 0.4786\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.3291 - accuracy: 0.4872\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3233 - accuracy: 0.5128\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3177 - accuracy: 0.5214\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3119 - accuracy: 0.5385\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3063 - accuracy: 0.5470\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3009 - accuracy: 0.5470\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2956 - accuracy: 0.5470\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2900 - accuracy: 0.5470\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2848 - accuracy: 0.5470\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2797 - accuracy: 0.5641\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2744 - accuracy: 0.5556\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2696 - accuracy: 0.5556\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2642 - accuracy: 0.5556\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2592 - accuracy: 0.5641\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2542 - accuracy: 0.5726\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2496 - accuracy: 0.5641\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2453 - accuracy: 0.5641\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2401 - accuracy: 0.5726\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2352 - accuracy: 0.5726\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2307 - accuracy: 0.5726\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2260 - accuracy: 0.5641\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2214 - accuracy: 0.5641\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2169 - accuracy: 0.5641\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2125 - accuracy: 0.5641\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2082 - accuracy: 0.5641\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2039 - accuracy: 0.5641\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1995 - accuracy: 0.5641\n",
      "Epoch 52/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1955 - accuracy: 0.5641\n",
      "Epoch 53/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1912 - accuracy: 0.5641\n",
      "Epoch 54/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1871 - accuracy: 0.5641\n",
      "Epoch 55/300\n",
      "117/117 [==============================] - 0s 162us/step - loss: 1.1832 - accuracy: 0.5641\n",
      "Epoch 56/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1789 - accuracy: 0.5641\n",
      "Epoch 57/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1749 - accuracy: 0.5641\n",
      "Epoch 58/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1711 - accuracy: 0.5726\n",
      "Epoch 59/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1670 - accuracy: 0.5726\n",
      "Epoch 60/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1630 - accuracy: 0.5726\n",
      "Epoch 61/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1594 - accuracy: 0.5726\n",
      "Epoch 62/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.1556 - accuracy: 0.5812\n",
      "Epoch 63/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1517 - accuracy: 0.5812\n",
      "Epoch 64/300\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.1482 - accuracy: 0.5726\n",
      "Epoch 65/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1445 - accuracy: 0.5812\n",
      "Epoch 66/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1409 - accuracy: 0.5897\n",
      "Epoch 67/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1371 - accuracy: 0.5726\n",
      "Epoch 68/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1339 - accuracy: 0.5726\n",
      "Epoch 69/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1303 - accuracy: 0.5726\n",
      "Epoch 70/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1271 - accuracy: 0.5726\n",
      "Epoch 71/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1232 - accuracy: 0.5726\n",
      "Epoch 72/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1198 - accuracy: 0.5726\n",
      "Epoch 73/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1164 - accuracy: 0.5726\n",
      "Epoch 74/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1131 - accuracy: 0.5726\n",
      "Epoch 75/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1101 - accuracy: 0.5726\n",
      "Epoch 76/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1067 - accuracy: 0.5726\n",
      "Epoch 77/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1036 - accuracy: 0.5726\n",
      "Epoch 78/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1002 - accuracy: 0.5812\n",
      "Epoch 79/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0972 - accuracy: 0.5812\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 1.0941 - accuracy: 0.5897\n",
      "Epoch 81/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0911 - accuracy: 0.5897\n",
      "Epoch 82/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0881 - accuracy: 0.5897\n",
      "Epoch 83/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0855 - accuracy: 0.5983\n",
      "Epoch 84/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0824 - accuracy: 0.5983\n",
      "Epoch 85/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0796 - accuracy: 0.5983\n",
      "Epoch 86/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0767 - accuracy: 0.5983\n",
      "Epoch 87/300\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.0737 - accuracy: 0.5983\n",
      "Epoch 88/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0709 - accuracy: 0.5983\n",
      "Epoch 89/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0683 - accuracy: 0.5983\n",
      "Epoch 90/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0656 - accuracy: 0.5983\n",
      "Epoch 91/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0631 - accuracy: 0.5983\n",
      "Epoch 92/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0604 - accuracy: 0.5983\n",
      "Epoch 93/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0578 - accuracy: 0.5983\n",
      "Epoch 94/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0552 - accuracy: 0.5983\n",
      "Epoch 95/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0530 - accuracy: 0.6068\n",
      "Epoch 96/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0503 - accuracy: 0.6068\n",
      "Epoch 97/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0478 - accuracy: 0.6154\n",
      "Epoch 98/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.0454 - accuracy: 0.6154\n",
      "Epoch 99/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0434 - accuracy: 0.6239\n",
      "Epoch 100/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0408 - accuracy: 0.6239\n",
      "Epoch 101/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0384 - accuracy: 0.6239\n",
      "Epoch 102/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0363 - accuracy: 0.6239\n",
      "Epoch 103/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0340 - accuracy: 0.6239\n",
      "Epoch 104/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0318 - accuracy: 0.6239\n",
      "Epoch 105/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0294 - accuracy: 0.6239\n",
      "Epoch 106/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0272 - accuracy: 0.6239\n",
      "Epoch 107/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0251 - accuracy: 0.6239\n",
      "Epoch 108/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0230 - accuracy: 0.6239\n",
      "Epoch 109/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0208 - accuracy: 0.6239\n",
      "Epoch 110/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0187 - accuracy: 0.6239\n",
      "Epoch 111/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0167 - accuracy: 0.6239\n",
      "Epoch 112/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0147 - accuracy: 0.6239\n",
      "Epoch 113/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0125 - accuracy: 0.6239\n",
      "Epoch 114/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0106 - accuracy: 0.6239\n",
      "Epoch 115/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0087 - accuracy: 0.6239\n",
      "Epoch 116/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0067 - accuracy: 0.6154\n",
      "Epoch 117/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0047 - accuracy: 0.6239\n",
      "Epoch 118/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0027 - accuracy: 0.6154\n",
      "Epoch 119/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0015 - accuracy: 0.6239\n",
      "Epoch 120/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9992 - accuracy: 0.6239\n",
      "Epoch 121/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9971 - accuracy: 0.6239\n",
      "Epoch 122/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9953 - accuracy: 0.6239\n",
      "Epoch 123/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9936 - accuracy: 0.6239\n",
      "Epoch 124/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9918 - accuracy: 0.6239\n",
      "Epoch 125/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9901 - accuracy: 0.6239\n",
      "Epoch 126/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9886 - accuracy: 0.6239\n",
      "Epoch 127/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9866 - accuracy: 0.6325\n",
      "Epoch 128/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9848 - accuracy: 0.6325\n",
      "Epoch 129/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9833 - accuracy: 0.6325\n",
      "Epoch 130/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9815 - accuracy: 0.6325\n",
      "Epoch 131/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9798 - accuracy: 0.6325\n",
      "Epoch 132/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9781 - accuracy: 0.6325\n",
      "Epoch 133/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9768 - accuracy: 0.6325\n",
      "Epoch 134/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9748 - accuracy: 0.6325\n",
      "Epoch 135/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9735 - accuracy: 0.6325\n",
      "Epoch 136/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9716 - accuracy: 0.6325\n",
      "Epoch 137/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9700 - accuracy: 0.6325\n",
      "Epoch 138/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9684 - accuracy: 0.6325\n",
      "Epoch 139/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0047 - accuracy: 0.58 - 0s 34us/step - loss: 0.9668 - accuracy: 0.6325\n",
      "Epoch 140/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9655 - accuracy: 0.6325\n",
      "Epoch 141/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9641 - accuracy: 0.6239\n",
      "Epoch 142/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9623 - accuracy: 0.6239\n",
      "Epoch 143/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9607 - accuracy: 0.6239\n",
      "Epoch 144/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9594 - accuracy: 0.6239\n",
      "Epoch 145/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9582 - accuracy: 0.6239\n",
      "Epoch 146/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9563 - accuracy: 0.6239\n",
      "Epoch 147/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9550 - accuracy: 0.6239\n",
      "Epoch 148/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9535 - accuracy: 0.6239\n",
      "Epoch 149/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9522 - accuracy: 0.6239\n",
      "Epoch 150/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9506 - accuracy: 0.6239\n",
      "Epoch 151/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9493 - accuracy: 0.6239\n",
      "Epoch 152/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9480 - accuracy: 0.6154\n",
      "Epoch 153/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9467 - accuracy: 0.6239\n",
      "Epoch 154/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9450 - accuracy: 0.6239\n",
      "Epoch 155/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9439 - accuracy: 0.6239\n",
      "Epoch 156/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9423 - accuracy: 0.6239\n",
      "Epoch 157/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9414 - accuracy: 0.6239\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 0.9398 - accuracy: 0.6239\n",
      "Epoch 159/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9386 - accuracy: 0.6239\n",
      "Epoch 160/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9371 - accuracy: 0.6239\n",
      "Epoch 161/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9357 - accuracy: 0.6239\n",
      "Epoch 162/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9345 - accuracy: 0.6239\n",
      "Epoch 163/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9333 - accuracy: 0.6325\n",
      "Epoch 164/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9321 - accuracy: 0.6325\n",
      "Epoch 165/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9310 - accuracy: 0.6325\n",
      "Epoch 166/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9296 - accuracy: 0.6325\n",
      "Epoch 167/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9285 - accuracy: 0.6325\n",
      "Epoch 168/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9273 - accuracy: 0.6410\n",
      "Epoch 169/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9265 - accuracy: 0.6410\n",
      "Epoch 170/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9248 - accuracy: 0.6410\n",
      "Epoch 171/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9240 - accuracy: 0.6496\n",
      "Epoch 172/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9226 - accuracy: 0.6496\n",
      "Epoch 173/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9216 - accuracy: 0.6496\n",
      "Epoch 174/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9202 - accuracy: 0.6496\n",
      "Epoch 175/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9190 - accuracy: 0.6496\n",
      "Epoch 176/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9180 - accuracy: 0.6496\n",
      "Epoch 177/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9167 - accuracy: 0.6496\n",
      "Epoch 178/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9159 - accuracy: 0.6581\n",
      "Epoch 179/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9144 - accuracy: 0.6581\n",
      "Epoch 180/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9135 - accuracy: 0.6581\n",
      "Epoch 181/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9123 - accuracy: 0.6581\n",
      "Epoch 182/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9110 - accuracy: 0.6581\n",
      "Epoch 183/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9103 - accuracy: 0.6581\n",
      "Epoch 184/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9092 - accuracy: 0.6581\n",
      "Epoch 185/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9084 - accuracy: 0.6581\n",
      "Epoch 186/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9069 - accuracy: 0.6581\n",
      "Epoch 187/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9057 - accuracy: 0.6581\n",
      "Epoch 188/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9048 - accuracy: 0.6581\n",
      "Epoch 189/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9037 - accuracy: 0.6581\n",
      "Epoch 190/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9027 - accuracy: 0.6581\n",
      "Epoch 191/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9025 - accuracy: 0.6581\n",
      "Epoch 192/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9008 - accuracy: 0.6496\n",
      "Epoch 193/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8995 - accuracy: 0.6496\n",
      "Epoch 194/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8987 - accuracy: 0.6496\n",
      "Epoch 195/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8979 - accuracy: 0.6496\n",
      "Epoch 196/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8965 - accuracy: 0.6496\n",
      "Epoch 197/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8957 - accuracy: 0.6496\n",
      "Epoch 198/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8946 - accuracy: 0.6496\n",
      "Epoch 199/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8941 - accuracy: 0.6496\n",
      "Epoch 200/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8927 - accuracy: 0.6496\n",
      "Epoch 201/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8921 - accuracy: 0.6496\n",
      "Epoch 202/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8909 - accuracy: 0.6496\n",
      "Epoch 203/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8905 - accuracy: 0.6581\n",
      "Epoch 204/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8891 - accuracy: 0.6496\n",
      "Epoch 205/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8881 - accuracy: 0.6496\n",
      "Epoch 206/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8871 - accuracy: 0.6496\n",
      "Epoch 207/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8862 - accuracy: 0.6496\n",
      "Epoch 208/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8856 - accuracy: 0.6496\n",
      "Epoch 209/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8844 - accuracy: 0.6496\n",
      "Epoch 210/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8836 - accuracy: 0.6496\n",
      "Epoch 211/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8826 - accuracy: 0.6496\n",
      "Epoch 212/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8818 - accuracy: 0.6496\n",
      "Epoch 213/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8811 - accuracy: 0.6581\n",
      "Epoch 214/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8799 - accuracy: 0.6581\n",
      "Epoch 215/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8790 - accuracy: 0.6581\n",
      "Epoch 216/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8782 - accuracy: 0.6581\n",
      "Epoch 217/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8775 - accuracy: 0.6581\n",
      "Epoch 218/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8766 - accuracy: 0.6581\n",
      "Epoch 219/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8759 - accuracy: 0.6581\n",
      "Epoch 220/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8747 - accuracy: 0.6581\n",
      "Epoch 221/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8739 - accuracy: 0.6581\n",
      "Epoch 222/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8734 - accuracy: 0.6581\n",
      "Epoch 223/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8730 - accuracy: 0.6581\n",
      "Epoch 224/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8716 - accuracy: 0.6581\n",
      "Epoch 225/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8706 - accuracy: 0.6581\n",
      "Epoch 226/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8699 - accuracy: 0.6667\n",
      "Epoch 227/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8691 - accuracy: 0.6581\n",
      "Epoch 228/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8681 - accuracy: 0.6581\n",
      "Epoch 229/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8674 - accuracy: 0.6581\n",
      "Epoch 230/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8665 - accuracy: 0.6581\n",
      "Epoch 231/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8658 - accuracy: 0.6581\n",
      "Epoch 232/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8650 - accuracy: 0.6667\n",
      "Epoch 233/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9064 - accuracy: 0.63 - 0s 145us/step - loss: 0.8641 - accuracy: 0.6667\n",
      "Epoch 234/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8634 - accuracy: 0.6667\n",
      "Epoch 235/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8625 - accuracy: 0.6667\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 0.8621 - accuracy: 0.6667\n",
      "Epoch 237/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8613 - accuracy: 0.6752\n",
      "Epoch 238/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8601 - accuracy: 0.6667\n",
      "Epoch 239/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8594 - accuracy: 0.6752\n",
      "Epoch 240/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8589 - accuracy: 0.6752\n",
      "Epoch 241/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8581 - accuracy: 0.6752\n",
      "Epoch 242/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8573 - accuracy: 0.6752\n",
      "Epoch 243/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8565 - accuracy: 0.6667\n",
      "Epoch 244/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8555 - accuracy: 0.6752\n",
      "Epoch 245/300\n",
      "117/117 [==============================] - 0s 119us/step - loss: 0.8549 - accuracy: 0.6752\n",
      "Epoch 246/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8539 - accuracy: 0.6752\n",
      "Epoch 247/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8533 - accuracy: 0.6752\n",
      "Epoch 248/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8527 - accuracy: 0.6752\n",
      "Epoch 249/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8524 - accuracy: 0.6752\n",
      "Epoch 250/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8516 - accuracy: 0.6752\n",
      "Epoch 251/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8502 - accuracy: 0.6752\n",
      "Epoch 252/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8498 - accuracy: 0.6752\n",
      "Epoch 253/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8489 - accuracy: 0.6752\n",
      "Epoch 254/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8480 - accuracy: 0.6752\n",
      "Epoch 255/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8474 - accuracy: 0.6752\n",
      "Epoch 256/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8468 - accuracy: 0.6752\n",
      "Epoch 257/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8462 - accuracy: 0.6752\n",
      "Epoch 258/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8452 - accuracy: 0.6752\n",
      "Epoch 259/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8448 - accuracy: 0.6752\n",
      "Epoch 260/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8437 - accuracy: 0.6752\n",
      "Epoch 261/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8437 - accuracy: 0.6752\n",
      "Epoch 262/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8424 - accuracy: 0.6752\n",
      "Epoch 263/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8418 - accuracy: 0.6752\n",
      "Epoch 264/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8412 - accuracy: 0.6752\n",
      "Epoch 265/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8404 - accuracy: 0.6752\n",
      "Epoch 266/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8399 - accuracy: 0.6752\n",
      "Epoch 267/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8400 - accuracy: 0.6667\n",
      "Epoch 268/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8384 - accuracy: 0.6752\n",
      "Epoch 269/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8376 - accuracy: 0.6752\n",
      "Epoch 270/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8377 - accuracy: 0.6752\n",
      "Epoch 271/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8365 - accuracy: 0.6752\n",
      "Epoch 272/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8358 - accuracy: 0.6752\n",
      "Epoch 273/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8352 - accuracy: 0.6752\n",
      "Epoch 274/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8345 - accuracy: 0.6752\n",
      "Epoch 275/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8339 - accuracy: 0.6752\n",
      "Epoch 276/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8335 - accuracy: 0.6752\n",
      "Epoch 277/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8325 - accuracy: 0.6752\n",
      "Epoch 278/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8321 - accuracy: 0.6752\n",
      "Epoch 279/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8315 - accuracy: 0.6752\n",
      "Epoch 280/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8307 - accuracy: 0.6752\n",
      "Epoch 281/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8302 - accuracy: 0.6752\n",
      "Epoch 282/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8298 - accuracy: 0.6752\n",
      "Epoch 283/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8293 - accuracy: 0.6752\n",
      "Epoch 284/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8283 - accuracy: 0.6752\n",
      "Epoch 285/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8277 - accuracy: 0.6752\n",
      "Epoch 286/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8270 - accuracy: 0.6752\n",
      "Epoch 287/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8265 - accuracy: 0.6752\n",
      "Epoch 288/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8260 - accuracy: 0.6752\n",
      "Epoch 289/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8251 - accuracy: 0.6752\n",
      "Epoch 290/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8247 - accuracy: 0.6752\n",
      "Epoch 291/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8245 - accuracy: 0.6752\n",
      "Epoch 292/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8238 - accuracy: 0.6752\n",
      "Epoch 293/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8233 - accuracy: 0.6752\n",
      "Epoch 294/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8228 - accuracy: 0.6752\n",
      "Epoch 295/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8218 - accuracy: 0.6752\n",
      "Epoch 296/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8212 - accuracy: 0.6752\n",
      "Epoch 297/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8208 - accuracy: 0.6838\n",
      "Epoch 298/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.8205 - accuracy: 0.6838\n",
      "Epoch 299/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8194 - accuracy: 0.6752\n",
      "Epoch 300/300\n",
      "117/117 [==============================] - 0s 332us/step - loss: 0.8191 - accuracy: 0.6752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20d23c45518>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=11, activation='relu')) # remove one layer\n",
    "model.add(Dense(32, activation='relu')) \n",
    "\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.569084</td>\n",
       "      <td>0.588571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.538462  0.536111   0.569084  0.588571    0     0    0   0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelevalobject = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Discuss which models performed better and point out relevant hyper-parameter values for successful models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model (model 3) performed best among all candidates. \n",
    "\n",
    "It is a neural network model with two hidden layers, each of which has 32 nodes. \n",
    "\n",
    "I think the reason why it performed better than the other two models is because it's simpler. Given we do not have many input data and the task is relatively simple, a complex model tend to suffer from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Submit your best model to the leader board for the World Happiness AI Model Share competition.\n",
    "\n",
    "You have the option to discuss these models in your report, but it is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I submitted the best model to AI Model Share competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('mymodel.onnx'):\n",
    "    from keras2onnx import convert_keras\n",
    "    onx = convert_keras(model, 'mymodel.onnx')\n",
    "    with open(\"mymodel.onnx\", \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading AWS keys necessary to submit model.  Loading to object, so we don't print them out in our notebook\n",
    "aws_key_password_region = pickle.load(open( \"data/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Model Pre-launched into Model Share Site\n",
    "apiurl=\"https://btuvanmi55.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "username = # removed when commit to github\n",
    "password = # removed when commit to github\n",
    "\n",
    "region='us-east-1'\n",
    "model_filepath=\"mymodel.onnx\"   \n",
    "preprocessor_filepath=\"preprocessor.pkl\"\n",
    "preprocessor=\"TRUE\"\n",
    "\n",
    "trainingdata=X_train\n",
    "\n",
    "# Set aws keys for this project (these keys give you access to collaborate on a single project)\n",
    "\n",
    "#Importing from object that stores keys so we do not print out keys for others to see.\n",
    "\n",
    "aws_key_password_region = pickle.load( open( \"data/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) )\n",
    "\n",
    "aws_key=aws_key_password_region[0]\n",
    "aws_password=aws_key_password_region[1]\n",
    "region=aws_key_password_region[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"mymodel.onnx\" has been loaded to version 71 of your prediction API.\n",
      "This version of the model will be used by your prediction api for all future predictions automatically.\n",
      "If you wish to use an older version of the model, please reference the getting started guide at aimodelshare.com.\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "\n",
    "ai.submit_model(model_filepath=model_filepath, model_eval_metrics=modelevalobject,apiurl=apiurl, username=username, password=password, aws_key=aws_key,aws_password=aws_password, region=region, trainingdata=trainingdata,preprocessor_filepath=preprocessor_filepath,preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEADERBOARD RANKINGS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>username</th>\n",
       "      <th>model_version</th>\n",
       "      <th>avg_ranking_classification</th>\n",
       "      <th>avg_ranking_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>70</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675975</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>69</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>62</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.646886</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>68</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.594805</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>67</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.625909</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>19</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.604242</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>37</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482925</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bavilaa</td>\n",
       "      <td>21</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482925</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bavilaa</td>\n",
       "      <td>20</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yaowang126</td>\n",
       "      <td>46</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>22</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>63</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>49</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>26</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>65</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>24</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sding</td>\n",
       "      <td>51</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>64</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>15</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>43</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.481021</td>\n",
       "      <td>0.595671</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>54</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>66</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>59</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461789</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>41</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.456259</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nayyer-Qureshi</td>\n",
       "      <td>13</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461789</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>47</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.461789</td>\n",
       "      <td>0.545714</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>55</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.456845</td>\n",
       "      <td>0.557576</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>27</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.464345</td>\n",
       "      <td>0.538162</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>56</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.456845</td>\n",
       "      <td>0.557576</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sding</td>\n",
       "      <td>40</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.419679</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ccabelloe</td>\n",
       "      <td>52</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.411048</td>\n",
       "      <td>0.437143</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>71</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>38</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>42</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>7</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>10</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>35</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>44</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>61</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>9</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>30</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>39</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>12</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>53</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>8</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>60</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>29</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nayyer-Qureshi</td>\n",
       "      <td>28</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>31</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>11</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XU</td>\n",
       "      <td>32</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>33</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>34</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>28</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ccabelloe</td>\n",
       "      <td>36</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.343861</td>\n",
       "      <td>0.348889</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>50</td>\n",
       "      <td>20.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.303896</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>18</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>6</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>2</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>3</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score  precision    recall  mse  rmse  mae  r2  \\\n",
       "31  0.717949  0.713796   0.719444  0.725000    0     0    0   0   \n",
       "67  0.666667  0.675975   0.754286  0.700952    0     0    0   0   \n",
       "32  0.692308  0.693333   0.700397  0.702778    0     0    0   0   \n",
       "41  0.641026  0.646886   0.738333  0.680952    0     0    0   0   \n",
       "9   0.589744  0.594805   0.714286  0.640952    0     0    0   0   \n",
       "12  0.512821  0.508060   0.625909  0.544444    0     0    0   0   \n",
       "36  0.512821  0.504464   0.604242  0.544444    0     0    0   0   \n",
       "27  0.487179  0.482925   0.605195  0.511111    0     0    0   0   \n",
       "20  0.487179  0.482925   0.605195  0.511111    0     0    0   0   \n",
       "37  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "29  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "47  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "48  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "52  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "53  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "33  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "0   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "19  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "1   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "14  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "64  0.487179  0.481021   0.595671  0.511111    0     0    0   0   \n",
       "2   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "7   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "61  0.461538  0.461789   0.545714  0.486111    0     0    0   0   \n",
       "63  0.461538  0.456259   0.576623  0.486111    0     0    0   0   \n",
       "44  0.461538  0.461789   0.545714  0.486111    0     0    0   0   \n",
       "5   0.461538  0.461789   0.545714  0.486111    0     0    0   0   \n",
       "57  0.461538  0.456845   0.557576  0.486111    0     0    0   0   \n",
       "13  0.461538  0.464345   0.538162  0.477778    0     0    0   0   \n",
       "60  0.461538  0.456845   0.557576  0.486111    0     0    0   0   \n",
       "..       ...       ...        ...       ...  ...   ...  ...  ..   \n",
       "18  0.410256  0.419679   0.503571  0.425000    0     0    0   0   \n",
       "24  0.410256  0.411048   0.437143  0.451429    0     0    0   0   \n",
       "38  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "8   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "65  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "11  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "62  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "17  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "59  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "56  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "39  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "54  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "55  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "22  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "28  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "43  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "26  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "21  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "46  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "25  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "49  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "50  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "51  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "23  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "35  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "66  0.384615  0.343861   0.348889  0.422222    0     0    0   0   \n",
       "10  0.384615  0.303896   0.340260  0.425000    0     0    0   0   \n",
       "15  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "58  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "3   0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "\n",
       "          username  model_version  avg_ranking_classification  \\\n",
       "31          3scman             70                    1.666667   \n",
       "67       dhoward97             69                    2.333333   \n",
       "32          3scman             62                    3.000000   \n",
       "41       dhoward97             68                    3.333333   \n",
       "9        dhoward97             67                    4.666667   \n",
       "12      Yihui_Wang             19                    6.000000   \n",
       "36   Paarth_Malkan             37                    7.000000   \n",
       "27         bavilaa             21                    7.333333   \n",
       "20         bavilaa             20                    7.333333   \n",
       "37      yaowang126             46                    8.666667   \n",
       "29          jaeham             22                    8.666667   \n",
       "47       dhoward97             63                    8.666667   \n",
       "48    seanmcalevey             49                    8.666667   \n",
       "52          Taketo             26                    8.666667   \n",
       "53       dhoward97             65                    8.666667   \n",
       "33         AlisaAi             24                    8.666667   \n",
       "0            sding             51                    8.666667   \n",
       "19       dhoward97             64                    8.666667   \n",
       "1          zivzach             15                    8.666667   \n",
       "14          Taketo             43                    8.666667   \n",
       "64      SUN-Wenjun             54                    8.666667   \n",
       "2        dhoward97             66                    8.666667   \n",
       "7           3scman             59                    8.666667   \n",
       "61        abhay_07             41                   11.666667   \n",
       "63  Nayyer-Qureshi             13                   11.666667   \n",
       "44        abhay_07             47                   11.666667   \n",
       "5         abhay_07             55                   11.666667   \n",
       "57    seanmcalevey             27                   12.000000   \n",
       "13       raquel904             56                   11.666667   \n",
       "60           sding             40                   12.000000   \n",
       "..             ...            ...                         ...   \n",
       "18       ccabelloe             52                   18.000000   \n",
       "24      SUN-Wenjun             71                   19.000000   \n",
       "38      Yihui_Wang             38                   19.333333   \n",
       "8    Paarth_Malkan             42                   19.333333   \n",
       "65       username2              7                   19.333333   \n",
       "11       username2             10                   19.333333   \n",
       "62          jaeham             35                   19.333333   \n",
       "17   Paarth_Malkan             44                   19.333333   \n",
       "59       dhoward97             61                   19.333333   \n",
       "56       username2              9                   19.333333   \n",
       "39         zivzach             30                   19.333333   \n",
       "54         AlisaAi             39                   19.333333   \n",
       "55       username2             12                   19.333333   \n",
       "22   Paarth_Malkan             53                   19.333333   \n",
       "28       username2              8                   19.333333   \n",
       "43    seanmcalevey             60                   19.333333   \n",
       "26    seanmcalevey             29                   19.333333   \n",
       "21  Nayyer-Qureshi             28                   19.333333   \n",
       "46        abhay_07             31                   19.333333   \n",
       "25       username2             11                   19.333333   \n",
       "49              XU             32                   19.333333   \n",
       "50          3scman             33                   19.333333   \n",
       "51          Taketo             34                   19.333333   \n",
       "23      SUN-Wenjun             28                   19.333333   \n",
       "35       ccabelloe             36                   19.333333   \n",
       "66         zivzach             50                   20.666667   \n",
       "10        abhay_07             18                   21.666667   \n",
       "15       username2              6                   21.000000   \n",
       "58       username2              2                   21.000000   \n",
       "3        username2              3                   21.000000   \n",
       "\n",
       "    avg_ranking_regression  \n",
       "31                     1.0  \n",
       "67                     1.0  \n",
       "32                     1.0  \n",
       "41                     1.0  \n",
       "9                      1.0  \n",
       "12                     1.0  \n",
       "36                     1.0  \n",
       "27                     1.0  \n",
       "20                     1.0  \n",
       "37                     1.0  \n",
       "29                     1.0  \n",
       "47                     1.0  \n",
       "48                     1.0  \n",
       "52                     1.0  \n",
       "53                     1.0  \n",
       "33                     1.0  \n",
       "0                      1.0  \n",
       "19                     1.0  \n",
       "1                      1.0  \n",
       "14                     1.0  \n",
       "64                     1.0  \n",
       "2                      1.0  \n",
       "7                      1.0  \n",
       "61                     1.0  \n",
       "63                     1.0  \n",
       "44                     1.0  \n",
       "5                      1.0  \n",
       "57                     1.0  \n",
       "13                     1.0  \n",
       "60                     1.0  \n",
       "..                     ...  \n",
       "18                     1.0  \n",
       "24                     1.0  \n",
       "38                     1.0  \n",
       "8                      1.0  \n",
       "65                     1.0  \n",
       "11                     1.0  \n",
       "62                     1.0  \n",
       "17                     1.0  \n",
       "59                     1.0  \n",
       "56                     1.0  \n",
       "39                     1.0  \n",
       "54                     1.0  \n",
       "55                     1.0  \n",
       "22                     1.0  \n",
       "28                     1.0  \n",
       "43                     1.0  \n",
       "26                     1.0  \n",
       "21                     1.0  \n",
       "46                     1.0  \n",
       "25                     1.0  \n",
       "49                     1.0  \n",
       "50                     1.0  \n",
       "51                     1.0  \n",
       "23                     1.0  \n",
       "35                     1.0  \n",
       "66                     1.0  \n",
       "10                     1.0  \n",
       "15                     1.0  \n",
       "58                     1.0  \n",
       "3                      1.0  \n",
       "\n",
       "[71 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "leaderboard = ai.get_leaderboard(apiurl, username, password, aws_key, aws_password, region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
