{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "link to my Github repo: https://github.com/SUN-Wenjun/Advanced_Machine_Learning_Assignment/tree/master/Assignment1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used countries as a categorical variable during our in class mini-hackathon.   This variable actually is categorical at the observation level.  Suffice it to say, in practice we do not really want to build a categorical variable using a variable that has as many categories as it we have observations in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import seed\n",
    "seed(5074)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(5074)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Merge datasets, add region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building your model replace the variable denoting country names with a new variable denoting world regions.  Here is a dataset you can use to merge in this data: https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/worldhappiness2019.csv\")\n",
    "\n",
    "regiondata = pd.read_csv(\"data/region.csv\")\n",
    "\n",
    "\n",
    "mergedata = pd.merge(data, regiondata, how='left', left_on='Country or region', right_on='name')\n",
    "# Check for missing values (there won't be any given that I have already cleaned up the region data)\n",
    "mergedata.loc[pd.isnull(mergedata).iloc[:,9]].to_csv(\"missing.csv\",index=False)\n",
    "\n",
    "# clean up final region data\n",
    "X = mergedata.drop(['Happiness_level', 'name', 'Country or region', 'sub-region'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GDP per capita  Social support  Healthy life expectancy  \\\n",
       "0           1.340           1.587                    0.986   \n",
       "1           1.383           1.573                    0.996   \n",
       "2           1.488           1.582                    1.028   \n",
       "3           1.380           1.624                    1.026   \n",
       "4           1.396           1.522                    0.999   \n",
       "\n",
       "   Freedom to make life choices  Generosity  Perceptions of corruption  region  \n",
       "0                         0.596       0.153                      0.393  Europe  \n",
       "1                         0.592       0.252                      0.410  Europe  \n",
       "2                         0.603       0.271                      0.341  Europe  \n",
       "3                         0.591       0.354                      0.118  Europe  \n",
       "4                         0.557       0.322                      0.298  Europe  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mergedata['Happiness_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explore bivariate results (Use visualizations!)\n",
    "\n",
    "Describe any relationships you see between particular features and the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['GDP per capita','Social support', 'Healthy life expectancy','Freedom to make life choices', 'Generosity', 'Perceptions of corruption']\n",
    "for feature in features:\n",
    "    ax = sns.boxplot(x='Happiness_level', y=feature, \n",
    "                     data=mergedata, \n",
    "                     order=['Very Low', 'Low', 'Average', 'High', 'Very High'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Variables that show a positive correlation with happiness level includes: GDP per capita, Social support, Healthy life expectancy, Freedom to make life choices. In other words, as these variables go higher, happiness level goes higher too.\n",
    "\n",
    "Generosity and Perceptions of corruption seem to have no clear correlation with happiness level from the box plots. Although it is interesting to find that countries with 'very high' level of happiness show a slightly higher perceptions of corruption, the varietion of this observation is relatively high. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.crosstab(mergedata['region'], mergedata['Happiness_level'])\n",
    "\n",
    "ax = df.plot.bar()\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(1.2, 0.8), ncol=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "When it comes to region, most countries in Europe have 'very high' happiness level, while countries in Africa are more in the range of 'very low' and 'low' level of happiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine features that predict happiness categories using one or more models that allow for automatic feature selection\n",
    "\n",
    "Explain any meaningful findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_features=X.columns.tolist()\n",
    "numeric_features.remove('region')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['region']\n",
    "\n",
    "#Replacing missing values with Modal value and then one hot encoding.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# final preprocessor object set up with ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "#Fit your preprocessor object\n",
    "prediction_input_preprocessor=preprocessor.fit(X_train) \n",
    "\n",
    "import pickle\n",
    "pickle.dump(prediction_input_preprocessor, open( \"preprocessor.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit a random forest model that allow for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "        max_features=None, norm_order=1, prefit=False, threshold=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 1000))\n",
    "sel.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, SelectFromModel will select the features whose importance is greater than the mean importance of all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "According to the result of feature selection, all the region (dummy) variables are considered less important for predicting happiness level than the average level of all the features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run at least three prediction models to try to predict World Happiness well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 11)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_input_preprocessor.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 0s 443us/step - loss: 1.6086 - accuracy: 0.1966\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6018 - accuracy: 0.2137\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5950 - accuracy: 0.2222\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5881 - accuracy: 0.2222\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5811 - accuracy: 0.2308\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5745 - accuracy: 0.2222\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5684 - accuracy: 0.2479\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5615 - accuracy: 0.2650\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5553 - accuracy: 0.2650\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5490 - accuracy: 0.2821\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5429 - accuracy: 0.2991\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5370 - accuracy: 0.3419\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5305 - accuracy: 0.3504\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5244 - accuracy: 0.3761\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5183 - accuracy: 0.4017\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5123 - accuracy: 0.4701\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5064 - accuracy: 0.4615\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5004 - accuracy: 0.4786\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4943 - accuracy: 0.4872\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4885 - accuracy: 0.4957\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4826 - accuracy: 0.4701\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4769 - accuracy: 0.4615\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4712 - accuracy: 0.4530\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4655 - accuracy: 0.4786\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4600 - accuracy: 0.4701\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4542 - accuracy: 0.4872\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4487 - accuracy: 0.4872\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4430 - accuracy: 0.4786\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4378 - accuracy: 0.4786\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4323 - accuracy: 0.4786\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4265 - accuracy: 0.4786\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4144 - accuracy: 0.51 - 0s 51us/step - loss: 1.4210 - accuracy: 0.4872\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4157 - accuracy: 0.4957\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4102 - accuracy: 0.4957\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4044 - accuracy: 0.5043\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3989 - accuracy: 0.5043\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3934 - accuracy: 0.5043\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3879 - accuracy: 0.4957\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3826 - accuracy: 0.5043\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3772 - accuracy: 0.5043\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3716 - accuracy: 0.4957\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3665 - accuracy: 0.4872\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3611 - accuracy: 0.5043\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3555 - accuracy: 0.4957\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3500 - accuracy: 0.4957\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3446 - accuracy: 0.5043\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3394 - accuracy: 0.5043\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3341 - accuracy: 0.5128\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3288 - accuracy: 0.5043\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3234 - accuracy: 0.5128\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3182 - accuracy: 0.5043\n",
      "Epoch 52/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3127 - accuracy: 0.5128\n",
      "Epoch 53/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3075 - accuracy: 0.5043\n",
      "Epoch 54/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3031 - accuracy: 0.5043\n",
      "Epoch 55/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2972 - accuracy: 0.5128\n",
      "Epoch 56/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2921 - accuracy: 0.5128\n",
      "Epoch 57/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2876 - accuracy: 0.5128\n",
      "Epoch 58/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2816 - accuracy: 0.5128\n",
      "Epoch 59/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2767 - accuracy: 0.5128\n",
      "Epoch 60/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2715 - accuracy: 0.5128\n",
      "Epoch 61/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2665 - accuracy: 0.5128\n",
      "Epoch 62/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2617 - accuracy: 0.5128\n",
      "Epoch 63/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2569 - accuracy: 0.5128\n",
      "Epoch 64/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2521 - accuracy: 0.5128\n",
      "Epoch 65/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2473 - accuracy: 0.5128\n",
      "Epoch 66/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2430 - accuracy: 0.5128\n",
      "Epoch 67/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2376 - accuracy: 0.5128\n",
      "Epoch 68/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2335 - accuracy: 0.5128\n",
      "Epoch 69/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2283 - accuracy: 0.5128\n",
      "Epoch 70/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2235 - accuracy: 0.5043\n",
      "Epoch 71/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2191 - accuracy: 0.5128\n",
      "Epoch 72/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2146 - accuracy: 0.5128\n",
      "Epoch 73/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2101 - accuracy: 0.5128\n",
      "Epoch 74/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2058 - accuracy: 0.5128\n",
      "Epoch 75/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2015 - accuracy: 0.5128\n",
      "Epoch 76/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1971 - accuracy: 0.5214\n",
      "Epoch 77/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1928 - accuracy: 0.5214\n",
      "Epoch 78/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1887 - accuracy: 0.5299\n",
      "Epoch 79/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1844 - accuracy: 0.5214\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 43us/step - loss: 1.1805 - accuracy: 0.5299\n",
      "Epoch 81/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1762 - accuracy: 0.5214\n",
      "Epoch 82/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1726 - accuracy: 0.5299\n",
      "Epoch 83/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1686 - accuracy: 0.5299\n",
      "Epoch 84/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1643 - accuracy: 0.5299\n",
      "Epoch 85/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1604 - accuracy: 0.5299\n",
      "Epoch 86/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1565 - accuracy: 0.5385\n",
      "Epoch 87/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1530 - accuracy: 0.5385\n",
      "Epoch 88/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1492 - accuracy: 0.5470\n",
      "Epoch 89/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1451 - accuracy: 0.5385\n",
      "Epoch 90/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1420 - accuracy: 0.5470\n",
      "Epoch 91/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1378 - accuracy: 0.5470\n",
      "Epoch 92/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1347 - accuracy: 0.5470\n",
      "Epoch 93/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1308 - accuracy: 0.5470\n",
      "Epoch 94/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1272 - accuracy: 0.5470\n",
      "Epoch 95/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1241 - accuracy: 0.5470\n",
      "Epoch 96/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1203 - accuracy: 0.5470\n",
      "Epoch 97/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1171 - accuracy: 0.5470\n",
      "Epoch 98/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1137 - accuracy: 0.5470\n",
      "Epoch 99/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1104 - accuracy: 0.5470\n",
      "Epoch 100/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1079 - accuracy: 0.5556\n",
      "Epoch 101/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1039 - accuracy: 0.5641\n",
      "Epoch 102/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1006 - accuracy: 0.5641\n",
      "Epoch 103/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0974 - accuracy: 0.5641\n",
      "Epoch 104/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0947 - accuracy: 0.5641\n",
      "Epoch 105/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0912 - accuracy: 0.5726\n",
      "Epoch 106/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0882 - accuracy: 0.5812\n",
      "Epoch 107/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0855 - accuracy: 0.5812\n",
      "Epoch 108/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0820 - accuracy: 0.5897\n",
      "Epoch 109/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0791 - accuracy: 0.5897\n",
      "Epoch 110/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0761 - accuracy: 0.5897\n",
      "Epoch 111/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0735 - accuracy: 0.5812\n",
      "Epoch 112/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0703 - accuracy: 0.5812\n",
      "Epoch 113/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0675 - accuracy: 0.5812\n",
      "Epoch 114/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0654 - accuracy: 0.5812\n",
      "Epoch 115/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0618 - accuracy: 0.5726\n",
      "Epoch 116/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0600 - accuracy: 0.5812\n",
      "Epoch 117/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0564 - accuracy: 0.5726\n",
      "Epoch 118/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0538 - accuracy: 0.5726\n",
      "Epoch 119/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0515 - accuracy: 0.5641\n",
      "Epoch 120/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0489 - accuracy: 0.5641\n",
      "Epoch 121/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0465 - accuracy: 0.5641\n",
      "Epoch 122/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0439 - accuracy: 0.5641\n",
      "Epoch 123/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0406 - accuracy: 0.5641\n",
      "Epoch 124/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0385 - accuracy: 0.5641\n",
      "Epoch 125/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0360 - accuracy: 0.5641\n",
      "Epoch 126/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0334 - accuracy: 0.5641\n",
      "Epoch 127/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0309 - accuracy: 0.5641\n",
      "Epoch 128/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0287 - accuracy: 0.5641\n",
      "Epoch 129/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0266 - accuracy: 0.5641\n",
      "Epoch 130/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.0557 - accuracy: 0.53 - 0s 51us/step - loss: 1.0235 - accuracy: 0.5641\n",
      "Epoch 131/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0218 - accuracy: 0.5641\n",
      "Epoch 132/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0201 - accuracy: 0.5641\n",
      "Epoch 133/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0167 - accuracy: 0.5641\n",
      "Epoch 134/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0145 - accuracy: 0.5641\n",
      "Epoch 135/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0119 - accuracy: 0.5641\n",
      "Epoch 136/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0100 - accuracy: 0.5641\n",
      "Epoch 137/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0076 - accuracy: 0.5641\n",
      "Epoch 138/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0056 - accuracy: 0.5641\n",
      "Epoch 139/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0032 - accuracy: 0.5641\n",
      "Epoch 140/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0007 - accuracy: 0.5641\n",
      "Epoch 141/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9993 - accuracy: 0.5641\n",
      "Epoch 142/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9964 - accuracy: 0.5726\n",
      "Epoch 143/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9947 - accuracy: 0.5726\n",
      "Epoch 144/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9938 - accuracy: 0.5812\n",
      "Epoch 145/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9912 - accuracy: 0.5812\n",
      "Epoch 146/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9883 - accuracy: 0.5812\n",
      "Epoch 147/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9866 - accuracy: 0.5812\n",
      "Epoch 148/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9845 - accuracy: 0.5812\n",
      "Epoch 149/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9826 - accuracy: 0.5812\n",
      "Epoch 150/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9802 - accuracy: 0.5812\n",
      "Epoch 151/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9787 - accuracy: 0.5812\n",
      "Epoch 152/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9768 - accuracy: 0.5812\n",
      "Epoch 153/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9745 - accuracy: 0.5812\n",
      "Epoch 154/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9728 - accuracy: 0.5812\n",
      "Epoch 155/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9706 - accuracy: 0.5812\n",
      "Epoch 156/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9686 - accuracy: 0.5812\n",
      "Epoch 157/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9667 - accuracy: 0.5812\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 43us/step - loss: 0.9651 - accuracy: 0.5897\n",
      "Epoch 159/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9632 - accuracy: 0.5897\n",
      "Epoch 160/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9618 - accuracy: 0.5897\n",
      "Epoch 161/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9598 - accuracy: 0.5897\n",
      "Epoch 162/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9579 - accuracy: 0.5897\n",
      "Epoch 163/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9565 - accuracy: 0.5897\n",
      "Epoch 164/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9545 - accuracy: 0.5983\n",
      "Epoch 165/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9528 - accuracy: 0.5983\n",
      "Epoch 166/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9510 - accuracy: 0.5897\n",
      "Epoch 167/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9497 - accuracy: 0.5983\n",
      "Epoch 168/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9477 - accuracy: 0.5983\n",
      "Epoch 169/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9461 - accuracy: 0.5983\n",
      "Epoch 170/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9448 - accuracy: 0.5897\n",
      "Epoch 171/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9429 - accuracy: 0.5983\n",
      "Epoch 172/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9418 - accuracy: 0.5983\n",
      "Epoch 173/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9399 - accuracy: 0.5897\n",
      "Epoch 174/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9381 - accuracy: 0.5897\n",
      "Epoch 175/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9360 - accuracy: 0.5897\n",
      "Epoch 176/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9348 - accuracy: 0.5983\n",
      "Epoch 177/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9331 - accuracy: 0.6068\n",
      "Epoch 178/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9318 - accuracy: 0.5983\n",
      "Epoch 179/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9305 - accuracy: 0.5983\n",
      "Epoch 180/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9298 - accuracy: 0.6154\n",
      "Epoch 181/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9285 - accuracy: 0.5983\n",
      "Epoch 182/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9255 - accuracy: 0.6068\n",
      "Epoch 183/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9241 - accuracy: 0.6154\n",
      "Epoch 184/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9232 - accuracy: 0.6154\n",
      "Epoch 185/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9212 - accuracy: 0.6154\n",
      "Epoch 186/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9200 - accuracy: 0.6154\n",
      "Epoch 187/300\n",
      "117/117 [==============================] - 0s 213us/step - loss: 0.9195 - accuracy: 0.6154\n",
      "Epoch 188/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9167 - accuracy: 0.6154\n",
      "Epoch 189/300\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9156 - accuracy: 0.6154\n",
      "Epoch 190/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9150 - accuracy: 0.6154\n",
      "Epoch 191/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9126 - accuracy: 0.6154\n",
      "Epoch 192/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9112 - accuracy: 0.6154\n",
      "Epoch 193/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9101 - accuracy: 0.6154\n",
      "Epoch 194/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9084 - accuracy: 0.6154\n",
      "Epoch 195/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9073 - accuracy: 0.6154\n",
      "Epoch 196/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9065 - accuracy: 0.6154\n",
      "Epoch 197/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9046 - accuracy: 0.6068\n",
      "Epoch 198/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9034 - accuracy: 0.6154\n",
      "Epoch 199/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9017 - accuracy: 0.6154\n",
      "Epoch 200/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9006 - accuracy: 0.6154\n",
      "Epoch 201/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8992 - accuracy: 0.6154\n",
      "Epoch 202/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8982 - accuracy: 0.6154\n",
      "Epoch 203/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8967 - accuracy: 0.6239\n",
      "Epoch 204/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8960 - accuracy: 0.6239\n",
      "Epoch 205/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8947 - accuracy: 0.6239\n",
      "Epoch 206/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8929 - accuracy: 0.6239\n",
      "Epoch 207/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8916 - accuracy: 0.6239\n",
      "Epoch 208/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8905 - accuracy: 0.6239\n",
      "Epoch 209/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8892 - accuracy: 0.6239\n",
      "Epoch 210/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8881 - accuracy: 0.6239\n",
      "Epoch 211/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8868 - accuracy: 0.6239\n",
      "Epoch 212/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8857 - accuracy: 0.6239\n",
      "Epoch 213/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8841 - accuracy: 0.6239\n",
      "Epoch 214/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8833 - accuracy: 0.6239\n",
      "Epoch 215/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8822 - accuracy: 0.6239\n",
      "Epoch 216/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8806 - accuracy: 0.6239\n",
      "Epoch 217/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8798 - accuracy: 0.6325\n",
      "Epoch 218/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8795 - accuracy: 0.6325\n",
      "Epoch 219/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8778 - accuracy: 0.6239\n",
      "Epoch 220/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8767 - accuracy: 0.6239\n",
      "Epoch 221/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8748 - accuracy: 0.6325\n",
      "Epoch 222/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8745 - accuracy: 0.6325\n",
      "Epoch 223/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8728 - accuracy: 0.6239\n",
      "Epoch 224/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8717 - accuracy: 0.6325\n",
      "Epoch 225/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8708 - accuracy: 0.6325\n",
      "Epoch 226/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8697 - accuracy: 0.6325\n",
      "Epoch 227/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8683 - accuracy: 0.6325\n",
      "Epoch 228/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8670 - accuracy: 0.6325\n",
      "Epoch 229/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8663 - accuracy: 0.6325\n",
      "Epoch 230/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8650 - accuracy: 0.6325\n",
      "Epoch 231/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8644 - accuracy: 0.6325\n",
      "Epoch 232/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8636 - accuracy: 0.6325\n",
      "Epoch 233/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8629 - accuracy: 0.6239\n",
      "Epoch 234/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8607 - accuracy: 0.6410\n",
      "Epoch 235/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8618 - accuracy: 0.6239\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 0.8592 - accuracy: 0.6410\n",
      "Epoch 237/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8580 - accuracy: 0.6410\n",
      "Epoch 238/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8568 - accuracy: 0.6410\n",
      "Epoch 239/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8559 - accuracy: 0.6325\n",
      "Epoch 240/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8546 - accuracy: 0.6410\n",
      "Epoch 241/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8537 - accuracy: 0.6410\n",
      "Epoch 242/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8526 - accuracy: 0.6496\n",
      "Epoch 243/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8517 - accuracy: 0.6496\n",
      "Epoch 244/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8506 - accuracy: 0.6496\n",
      "Epoch 245/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8502 - accuracy: 0.6496\n",
      "Epoch 246/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8490 - accuracy: 0.6496\n",
      "Epoch 247/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8484 - accuracy: 0.6410\n",
      "Epoch 248/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8468 - accuracy: 0.6496\n",
      "Epoch 249/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8462 - accuracy: 0.6496\n",
      "Epoch 250/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8449 - accuracy: 0.6496\n",
      "Epoch 251/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8441 - accuracy: 0.6496\n",
      "Epoch 252/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8435 - accuracy: 0.6496\n",
      "Epoch 253/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8422 - accuracy: 0.6496\n",
      "Epoch 254/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8409 - accuracy: 0.6496\n",
      "Epoch 255/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8404 - accuracy: 0.6410\n",
      "Epoch 256/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8391 - accuracy: 0.6496\n",
      "Epoch 257/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8387 - accuracy: 0.6496\n",
      "Epoch 258/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8371 - accuracy: 0.6496\n",
      "Epoch 259/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8361 - accuracy: 0.6496\n",
      "Epoch 260/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8352 - accuracy: 0.6496\n",
      "Epoch 261/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8345 - accuracy: 0.6496\n",
      "Epoch 262/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8343 - accuracy: 0.6325\n",
      "Epoch 263/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8329 - accuracy: 0.6496\n",
      "Epoch 264/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8323 - accuracy: 0.6496\n",
      "Epoch 265/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8309 - accuracy: 0.6496\n",
      "Epoch 266/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8301 - accuracy: 0.6410\n",
      "Epoch 267/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8291 - accuracy: 0.6496\n",
      "Epoch 268/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8281 - accuracy: 0.6496\n",
      "Epoch 269/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8278 - accuracy: 0.6325\n",
      "Epoch 270/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8263 - accuracy: 0.6496\n",
      "Epoch 271/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8261 - accuracy: 0.6325\n",
      "Epoch 272/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8250 - accuracy: 0.6496\n",
      "Epoch 273/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8241 - accuracy: 0.6496\n",
      "Epoch 274/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8227 - accuracy: 0.6496\n",
      "Epoch 275/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8228 - accuracy: 0.6410\n",
      "Epoch 276/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8220 - accuracy: 0.6410\n",
      "Epoch 277/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8211 - accuracy: 0.6410\n",
      "Epoch 278/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8198 - accuracy: 0.6410\n",
      "Epoch 279/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8185 - accuracy: 0.6325\n",
      "Epoch 280/300\n",
      "117/117 [==============================] - 0s 111us/step - loss: 0.8184 - accuracy: 0.6410\n",
      "Epoch 281/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8178 - accuracy: 0.6496\n",
      "Epoch 282/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8164 - accuracy: 0.6410\n",
      "Epoch 283/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8157 - accuracy: 0.6410\n",
      "Epoch 284/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8148 - accuracy: 0.6239\n",
      "Epoch 285/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8154 - accuracy: 0.6325\n",
      "Epoch 286/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8131 - accuracy: 0.6325\n",
      "Epoch 287/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8125 - accuracy: 0.6239\n",
      "Epoch 288/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8123 - accuracy: 0.6325\n",
      "Epoch 289/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8103 - accuracy: 0.6325\n",
      "Epoch 290/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8104 - accuracy: 0.6325\n",
      "Epoch 291/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8092 - accuracy: 0.6239\n",
      "Epoch 292/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8080 - accuracy: 0.6410\n",
      "Epoch 293/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8079 - accuracy: 0.6410\n",
      "Epoch 294/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8069 - accuracy: 0.6239\n",
      "Epoch 295/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8058 - accuracy: 0.6410\n",
      "Epoch 296/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8058 - accuracy: 0.6239\n",
      "Epoch 297/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8039 - accuracy: 0.6154\n",
      "Epoch 298/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8044 - accuracy: 0.6239\n",
      "Epoch 299/300\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8038 - accuracy: 0.6239\n",
      "Epoch 300/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8021 - accuracy: 0.6496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x213e265cf28>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(124, input_dim=11, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "model1.add(Dense(124, activation='relu'))\n",
    "\n",
    "model1.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model1.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model1.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.63916</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.641026   0.63916   0.660476  0.700455    0     0    0   0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "def model_eval_metrics(y_true, y_pred,classification=\"TRUE\"):\n",
    "     if classification==\"TRUE\":\n",
    "        accuracy_eval = accuracy_score(y_true, y_pred)\n",
    "        f1_score_eval = f1_score(y_true, y_pred,average=\"macro\")\n",
    "        precision_eval = precision_score(y_true, y_pred,average=\"macro\")\n",
    "        recall_eval = recall_score(y_true, y_pred,average=\"macro\")\n",
    "        mse_eval = 0\n",
    "        rmse_eval = 0\n",
    "        mae_eval = 0\n",
    "        r2_eval = 0\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     else:\n",
    "        accuracy_eval = 0\n",
    "        f1_score_eval = 0\n",
    "        precision_eval = 0\n",
    "        recall_eval = 0\n",
    "        mse_eval = mean_squared_error(y_true, y_pred)\n",
    "        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae_eval = mean_absolute_error(y_true, y_pred)\n",
    "        r2_eval = r2_score(y_true, y_pred)\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     return finalmetricdata\n",
    "\n",
    "modelevalobject1 = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "117/117 [==============================] - 0s 443us/step - loss: 1.5979 - accuracy: 0.2308\n",
      "Epoch 2/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5912 - accuracy: 0.2308\n",
      "Epoch 3/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5848 - accuracy: 0.2308\n",
      "Epoch 4/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5788 - accuracy: 0.2308\n",
      "Epoch 5/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5728 - accuracy: 0.2479\n",
      "Epoch 6/300\n",
      "117/117 [==============================] - 0s 42us/step - loss: 1.5672 - accuracy: 0.2650\n",
      "Epoch 7/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.5615 - accuracy: 0.2650\n",
      "Epoch 8/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5564 - accuracy: 0.2906\n",
      "Epoch 9/300\n",
      "117/117 [==============================] - 0s 298us/step - loss: 1.5510 - accuracy: 0.3077\n",
      "Epoch 10/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5458 - accuracy: 0.3162\n",
      "Epoch 11/300\n",
      "117/117 [==============================] - 0s 239us/step - loss: 1.5408 - accuracy: 0.3248\n",
      "Epoch 12/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5357 - accuracy: 0.3419\n",
      "Epoch 13/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5305 - accuracy: 0.3248\n",
      "Epoch 14/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5256 - accuracy: 0.3504\n",
      "Epoch 15/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5207 - accuracy: 0.3419\n",
      "Epoch 16/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5162 - accuracy: 0.3333\n",
      "Epoch 17/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5109 - accuracy: 0.3333\n",
      "Epoch 18/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.5067 - accuracy: 0.3419\n",
      "Epoch 19/300\n",
      "117/117 [==============================] - 0s 188us/step - loss: 1.5015 - accuracy: 0.3504\n",
      "Epoch 20/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4969 - accuracy: 0.3675\n",
      "Epoch 21/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4926 - accuracy: 0.3761\n",
      "Epoch 22/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4883 - accuracy: 0.3932\n",
      "Epoch 23/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4831 - accuracy: 0.3932\n",
      "Epoch 24/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4787 - accuracy: 0.4017\n",
      "Epoch 25/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4741 - accuracy: 0.4103\n",
      "Epoch 26/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4695 - accuracy: 0.3932\n",
      "Epoch 27/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4652 - accuracy: 0.3932\n",
      "Epoch 28/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4606 - accuracy: 0.3846\n",
      "Epoch 29/300\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4560 - accuracy: 0.3932\n",
      "Epoch 30/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4521 - accuracy: 0.4017\n",
      "Epoch 31/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4474 - accuracy: 0.4103\n",
      "Epoch 32/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4429 - accuracy: 0.4103\n",
      "Epoch 33/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4385 - accuracy: 0.4188\n",
      "Epoch 34/300\n",
      "117/117 [==============================] - 0s 205us/step - loss: 1.4341 - accuracy: 0.4103\n",
      "Epoch 35/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4297 - accuracy: 0.4103\n",
      "Epoch 36/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4252 - accuracy: 0.4103\n",
      "Epoch 37/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.4208 - accuracy: 0.4017\n",
      "Epoch 38/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4165 - accuracy: 0.3932\n",
      "Epoch 39/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4129 - accuracy: 0.4188\n",
      "Epoch 40/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4083 - accuracy: 0.4188\n",
      "Epoch 41/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.4038 - accuracy: 0.4274\n",
      "Epoch 42/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3996 - accuracy: 0.4359\n",
      "Epoch 43/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3955 - accuracy: 0.4359\n",
      "Epoch 44/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3915 - accuracy: 0.4359\n",
      "Epoch 45/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3874 - accuracy: 0.4359\n",
      "Epoch 46/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3831 - accuracy: 0.4359\n",
      "Epoch 47/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3792 - accuracy: 0.4359\n",
      "Epoch 48/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3749 - accuracy: 0.4359\n",
      "Epoch 49/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3711 - accuracy: 0.4359\n",
      "Epoch 50/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3670 - accuracy: 0.4359\n",
      "Epoch 51/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3630 - accuracy: 0.4444\n",
      "Epoch 52/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3590 - accuracy: 0.4444\n",
      "Epoch 53/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3550 - accuracy: 0.4530\n",
      "Epoch 54/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3511 - accuracy: 0.4530\n",
      "Epoch 55/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3471 - accuracy: 0.4530\n",
      "Epoch 56/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3433 - accuracy: 0.4530\n",
      "Epoch 57/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3394 - accuracy: 0.4530\n",
      "Epoch 58/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3354 - accuracy: 0.4530\n",
      "Epoch 59/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3321 - accuracy: 0.4530\n",
      "Epoch 60/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3276 - accuracy: 0.4530\n",
      "Epoch 61/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3238 - accuracy: 0.4530\n",
      "Epoch 62/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3203 - accuracy: 0.4530\n",
      "Epoch 63/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3160 - accuracy: 0.4615\n",
      "Epoch 64/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3125 - accuracy: 0.4615\n",
      "Epoch 65/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3087 - accuracy: 0.4615\n",
      "Epoch 66/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3044 - accuracy: 0.4615\n",
      "Epoch 67/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.3005 - accuracy: 0.4615\n",
      "Epoch 68/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2969 - accuracy: 0.4615\n",
      "Epoch 69/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2930 - accuracy: 0.4615\n",
      "Epoch 70/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2892 - accuracy: 0.4615\n",
      "Epoch 71/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2855 - accuracy: 0.4615\n",
      "Epoch 72/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2815 - accuracy: 0.4615\n",
      "Epoch 73/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.2777 - accuracy: 0.4615\n",
      "Epoch 74/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2741 - accuracy: 0.4615\n",
      "Epoch 75/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2707 - accuracy: 0.4615\n",
      "Epoch 76/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2667 - accuracy: 0.4615\n",
      "Epoch 77/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2628 - accuracy: 0.4530\n",
      "Epoch 78/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2591 - accuracy: 0.4615\n",
      "Epoch 79/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2556 - accuracy: 0.4530\n",
      "Epoch 80/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 1.2520 - accuracy: 0.4530\n",
      "Epoch 81/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2487 - accuracy: 0.4530\n",
      "Epoch 82/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2450 - accuracy: 0.4530\n",
      "Epoch 83/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2414 - accuracy: 0.4530\n",
      "Epoch 84/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2379 - accuracy: 0.4530\n",
      "Epoch 85/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2344 - accuracy: 0.4530\n",
      "Epoch 86/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2309 - accuracy: 0.4530\n",
      "Epoch 87/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2277 - accuracy: 0.4530\n",
      "Epoch 88/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2241 - accuracy: 0.4530\n",
      "Epoch 89/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.2205 - accuracy: 0.4530\n",
      "Epoch 90/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2173 - accuracy: 0.4530\n",
      "Epoch 91/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2138 - accuracy: 0.4530\n",
      "Epoch 92/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2105 - accuracy: 0.4530\n",
      "Epoch 93/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.2073 - accuracy: 0.4530\n",
      "Epoch 94/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2044 - accuracy: 0.4530\n",
      "Epoch 95/300\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.2176 - accuracy: 0.43 - 0s 34us/step - loss: 1.2009 - accuracy: 0.4615\n",
      "Epoch 96/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1975 - accuracy: 0.4615\n",
      "Epoch 97/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1945 - accuracy: 0.4615\n",
      "Epoch 98/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1914 - accuracy: 0.4615\n",
      "Epoch 99/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1884 - accuracy: 0.4615\n",
      "Epoch 100/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1849 - accuracy: 0.4701\n",
      "Epoch 101/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1817 - accuracy: 0.4701\n",
      "Epoch 102/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1788 - accuracy: 0.4701\n",
      "Epoch 103/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1759 - accuracy: 0.4786\n",
      "Epoch 104/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1734 - accuracy: 0.4786\n",
      "Epoch 105/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1698 - accuracy: 0.4872\n",
      "Epoch 106/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1669 - accuracy: 0.4872\n",
      "Epoch 107/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1635 - accuracy: 0.4957\n",
      "Epoch 108/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1606 - accuracy: 0.4957\n",
      "Epoch 109/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1578 - accuracy: 0.5043\n",
      "Epoch 110/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1547 - accuracy: 0.5043\n",
      "Epoch 111/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1516 - accuracy: 0.5043\n",
      "Epoch 112/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1489 - accuracy: 0.5128\n",
      "Epoch 113/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1460 - accuracy: 0.5128\n",
      "Epoch 114/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1429 - accuracy: 0.5128\n",
      "Epoch 115/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1407 - accuracy: 0.5128\n",
      "Epoch 116/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1381 - accuracy: 0.5128\n",
      "Epoch 117/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 1.1346 - accuracy: 0.5214\n",
      "Epoch 118/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1324 - accuracy: 0.5214\n",
      "Epoch 119/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1293 - accuracy: 0.5299\n",
      "Epoch 120/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1264 - accuracy: 0.5299\n",
      "Epoch 121/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1240 - accuracy: 0.5299\n",
      "Epoch 122/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1211 - accuracy: 0.5299\n",
      "Epoch 123/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1186 - accuracy: 0.5299\n",
      "Epoch 124/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1160 - accuracy: 0.5299\n",
      "Epoch 125/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1131 - accuracy: 0.5299\n",
      "Epoch 126/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1107 - accuracy: 0.5299\n",
      "Epoch 127/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1083 - accuracy: 0.5299\n",
      "Epoch 128/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1058 - accuracy: 0.5299\n",
      "Epoch 129/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1036 - accuracy: 0.5299\n",
      "Epoch 130/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.1007 - accuracy: 0.5299\n",
      "Epoch 131/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0988 - accuracy: 0.5299\n",
      "Epoch 132/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0960 - accuracy: 0.5299\n",
      "Epoch 133/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0938 - accuracy: 0.5299\n",
      "Epoch 134/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0916 - accuracy: 0.5299\n",
      "Epoch 135/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0890 - accuracy: 0.5299\n",
      "Epoch 136/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0865 - accuracy: 0.5385\n",
      "Epoch 137/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0842 - accuracy: 0.5299\n",
      "Epoch 138/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0816 - accuracy: 0.5385\n",
      "Epoch 139/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0796 - accuracy: 0.5299\n",
      "Epoch 140/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0770 - accuracy: 0.5385\n",
      "Epoch 141/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0751 - accuracy: 0.5299\n",
      "Epoch 142/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0726 - accuracy: 0.5470\n",
      "Epoch 143/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0708 - accuracy: 0.5470\n",
      "Epoch 144/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0684 - accuracy: 0.5385\n",
      "Epoch 145/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0659 - accuracy: 0.5385\n",
      "Epoch 146/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0643 - accuracy: 0.5385\n",
      "Epoch 147/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0622 - accuracy: 0.5385\n",
      "Epoch 148/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0597 - accuracy: 0.5385\n",
      "Epoch 149/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0576 - accuracy: 0.5385\n",
      "Epoch 150/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0558 - accuracy: 0.5299\n",
      "Epoch 151/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0535 - accuracy: 0.5299\n",
      "Epoch 152/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0512 - accuracy: 0.5299\n",
      "Epoch 153/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0491 - accuracy: 0.5299\n",
      "Epoch 154/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0472 - accuracy: 0.5299\n",
      "Epoch 155/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0452 - accuracy: 0.5299\n",
      "Epoch 156/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0432 - accuracy: 0.5299\n",
      "Epoch 157/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0411 - accuracy: 0.5299\n",
      "Epoch 158/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 34us/step - loss: 1.0400 - accuracy: 0.5299\n",
      "Epoch 159/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0381 - accuracy: 0.5299\n",
      "Epoch 160/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0357 - accuracy: 0.5299\n",
      "Epoch 161/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0335 - accuracy: 0.5299\n",
      "Epoch 162/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0316 - accuracy: 0.5299\n",
      "Epoch 163/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0298 - accuracy: 0.5299\n",
      "Epoch 164/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0280 - accuracy: 0.5299\n",
      "Epoch 165/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0266 - accuracy: 0.5299\n",
      "Epoch 166/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0249 - accuracy: 0.5299\n",
      "Epoch 167/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0228 - accuracy: 0.5299\n",
      "Epoch 168/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0205 - accuracy: 0.5385\n",
      "Epoch 169/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0189 - accuracy: 0.5385\n",
      "Epoch 170/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0170 - accuracy: 0.5385\n",
      "Epoch 171/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0157 - accuracy: 0.5470\n",
      "Epoch 172/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0139 - accuracy: 0.5556\n",
      "Epoch 173/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0134 - accuracy: 0.5556\n",
      "Epoch 174/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0100 - accuracy: 0.5556\n",
      "Epoch 175/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0090 - accuracy: 0.5556\n",
      "Epoch 176/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0070 - accuracy: 0.5556\n",
      "Epoch 177/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 1.0050 - accuracy: 0.5556\n",
      "Epoch 178/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0031 - accuracy: 0.5556\n",
      "Epoch 179/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0016 - accuracy: 0.5556\n",
      "Epoch 180/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9998 - accuracy: 0.5470\n",
      "Epoch 181/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9985 - accuracy: 0.5556\n",
      "Epoch 182/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9968 - accuracy: 0.5556\n",
      "Epoch 183/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9949 - accuracy: 0.5556\n",
      "Epoch 184/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9934 - accuracy: 0.5556\n",
      "Epoch 185/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9920 - accuracy: 0.5556\n",
      "Epoch 186/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9903 - accuracy: 0.5556\n",
      "Epoch 187/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9890 - accuracy: 0.5556\n",
      "Epoch 188/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9870 - accuracy: 0.5726\n",
      "Epoch 189/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9857 - accuracy: 0.5641\n",
      "Epoch 190/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9842 - accuracy: 0.5726\n",
      "Epoch 191/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9826 - accuracy: 0.5726\n",
      "Epoch 192/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9822 - accuracy: 0.5641\n",
      "Epoch 193/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9796 - accuracy: 0.5726\n",
      "Epoch 194/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9782 - accuracy: 0.5726\n",
      "Epoch 195/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9764 - accuracy: 0.5726\n",
      "Epoch 196/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9752 - accuracy: 0.5726\n",
      "Epoch 197/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9738 - accuracy: 0.5726\n",
      "Epoch 198/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9721 - accuracy: 0.5726\n",
      "Epoch 199/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9705 - accuracy: 0.5726\n",
      "Epoch 200/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9696 - accuracy: 0.5726\n",
      "Epoch 201/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9681 - accuracy: 0.5726\n",
      "Epoch 202/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9668 - accuracy: 0.5726\n",
      "Epoch 203/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9650 - accuracy: 0.5726\n",
      "Epoch 204/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9636 - accuracy: 0.5726\n",
      "Epoch 205/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9620 - accuracy: 0.5726\n",
      "Epoch 206/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9610 - accuracy: 0.5726\n",
      "Epoch 207/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9595 - accuracy: 0.5726\n",
      "Epoch 208/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9589 - accuracy: 0.5726\n",
      "Epoch 209/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9568 - accuracy: 0.5726\n",
      "Epoch 210/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9556 - accuracy: 0.5726\n",
      "Epoch 211/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9542 - accuracy: 0.5726\n",
      "Epoch 212/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9528 - accuracy: 0.5726\n",
      "Epoch 213/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9516 - accuracy: 0.5726\n",
      "Epoch 214/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9504 - accuracy: 0.5812\n",
      "Epoch 215/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9487 - accuracy: 0.5726\n",
      "Epoch 216/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9481 - accuracy: 0.5726\n",
      "Epoch 217/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9467 - accuracy: 0.5726\n",
      "Epoch 218/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9450 - accuracy: 0.5897\n",
      "Epoch 219/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9445 - accuracy: 0.5812\n",
      "Epoch 220/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9424 - accuracy: 0.5812\n",
      "Epoch 221/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9415 - accuracy: 0.5897\n",
      "Epoch 222/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9398 - accuracy: 0.5983\n",
      "Epoch 223/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9387 - accuracy: 0.5983\n",
      "Epoch 224/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9377 - accuracy: 0.5897\n",
      "Epoch 225/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9360 - accuracy: 0.5983\n",
      "Epoch 226/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9351 - accuracy: 0.5983\n",
      "Epoch 227/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9353 - accuracy: 0.5983\n",
      "Epoch 228/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9324 - accuracy: 0.6068\n",
      "Epoch 229/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9314 - accuracy: 0.6068\n",
      "Epoch 230/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9305 - accuracy: 0.6068\n",
      "Epoch 231/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9289 - accuracy: 0.6068\n",
      "Epoch 232/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9289 - accuracy: 0.5983\n",
      "Epoch 233/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9268 - accuracy: 0.5983\n",
      "Epoch 234/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9252 - accuracy: 0.5983\n",
      "Epoch 235/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9240 - accuracy: 0.6068\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 43us/step - loss: 0.9228 - accuracy: 0.6068\n",
      "Epoch 237/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9229 - accuracy: 0.6068\n",
      "Epoch 238/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9216 - accuracy: 0.6068\n",
      "Epoch 239/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9197 - accuracy: 0.6068\n",
      "Epoch 240/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9205 - accuracy: 0.6068\n",
      "Epoch 241/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9173 - accuracy: 0.6068\n",
      "Epoch 242/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9161 - accuracy: 0.6068\n",
      "Epoch 243/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9159 - accuracy: 0.6154\n",
      "Epoch 244/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9139 - accuracy: 0.6068\n",
      "Epoch 245/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9136 - accuracy: 0.6154\n",
      "Epoch 246/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9120 - accuracy: 0.6068\n",
      "Epoch 247/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9115 - accuracy: 0.6068\n",
      "Epoch 248/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9095 - accuracy: 0.6068\n",
      "Epoch 249/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9084 - accuracy: 0.6068\n",
      "Epoch 250/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9074 - accuracy: 0.6068\n",
      "Epoch 251/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9068 - accuracy: 0.6068\n",
      "Epoch 252/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9052 - accuracy: 0.6068\n",
      "Epoch 253/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9048 - accuracy: 0.6068\n",
      "Epoch 254/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9038 - accuracy: 0.6068\n",
      "Epoch 255/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9021 - accuracy: 0.6068\n",
      "Epoch 256/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9011 - accuracy: 0.6068\n",
      "Epoch 257/300\n",
      "117/117 [==============================] - 0s 26us/step - loss: 0.9010 - accuracy: 0.6068\n",
      "Epoch 258/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.9001 - accuracy: 0.6068\n",
      "Epoch 259/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8984 - accuracy: 0.6068\n",
      "Epoch 260/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8976 - accuracy: 0.6068\n",
      "Epoch 261/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8962 - accuracy: 0.6068\n",
      "Epoch 262/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8970 - accuracy: 0.6154\n",
      "Epoch 263/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8949 - accuracy: 0.6068\n",
      "Epoch 264/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8937 - accuracy: 0.6068\n",
      "Epoch 265/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8932 - accuracy: 0.6068\n",
      "Epoch 266/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8912 - accuracy: 0.6068\n",
      "Epoch 267/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8904 - accuracy: 0.6068\n",
      "Epoch 268/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8896 - accuracy: 0.6068\n",
      "Epoch 269/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8895 - accuracy: 0.6068\n",
      "Epoch 270/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8877 - accuracy: 0.6068\n",
      "Epoch 271/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8869 - accuracy: 0.6068\n",
      "Epoch 272/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8854 - accuracy: 0.6068\n",
      "Epoch 273/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8851 - accuracy: 0.6068\n",
      "Epoch 274/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8840 - accuracy: 0.6154\n",
      "Epoch 275/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8826 - accuracy: 0.6068\n",
      "Epoch 276/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8818 - accuracy: 0.6068\n",
      "Epoch 277/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8809 - accuracy: 0.6068\n",
      "Epoch 278/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8808 - accuracy: 0.6068\n",
      "Epoch 279/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8791 - accuracy: 0.6068\n",
      "Epoch 280/300\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8784 - accuracy: 0.6068\n",
      "Epoch 281/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8773 - accuracy: 0.6068\n",
      "Epoch 282/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8767 - accuracy: 0.6068\n",
      "Epoch 283/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8758 - accuracy: 0.6154\n",
      "Epoch 284/300\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8746 - accuracy: 0.6154\n",
      "Epoch 285/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8743 - accuracy: 0.6154\n",
      "Epoch 286/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8731 - accuracy: 0.6068\n",
      "Epoch 287/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8724 - accuracy: 0.6154\n",
      "Epoch 288/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8718 - accuracy: 0.6154\n",
      "Epoch 289/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8706 - accuracy: 0.6154\n",
      "Epoch 290/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8702 - accuracy: 0.6154\n",
      "Epoch 291/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8692 - accuracy: 0.6154\n",
      "Epoch 292/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8683 - accuracy: 0.6068\n",
      "Epoch 293/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8673 - accuracy: 0.6154\n",
      "Epoch 294/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8663 - accuracy: 0.6154\n",
      "Epoch 295/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8655 - accuracy: 0.6154\n",
      "Epoch 296/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8650 - accuracy: 0.6154\n",
      "Epoch 297/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8646 - accuracy: 0.6154\n",
      "Epoch 298/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8633 - accuracy: 0.6154\n",
      "Epoch 299/300\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.8628 - accuracy: 0.6154\n",
      "Epoch 300/300\n",
      "117/117 [==============================] - 0s 34us/step - loss: 0.8622 - accuracy: 0.6154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x213e26fcb38>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(32, input_dim=11, activation='relu')) # change dense to 32\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "\n",
    "model2.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model2.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model2.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.59641</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.615385   0.59641   0.614286  0.643636    0     0    0   0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelevalobject2 = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "117/117 [==============================] - 0s 1ms/step - loss: 1.6813 - accuracy: 0.1709\n",
      "Epoch 2/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6595 - accuracy: 0.2222\n",
      "Epoch 3/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6575 - accuracy: 0.2308\n",
      "Epoch 4/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6483 - accuracy: 0.2650\n",
      "Epoch 5/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6617 - accuracy: 0.2479\n",
      "Epoch 6/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.7138 - accuracy: 0.2051\n",
      "Epoch 7/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6352 - accuracy: 0.1709\n",
      "Epoch 8/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.6635 - accuracy: 0.2479\n",
      "Epoch 9/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6413 - accuracy: 0.2821\n",
      "Epoch 10/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6133 - accuracy: 0.1624\n",
      "Epoch 11/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6120 - accuracy: 0.2222\n",
      "Epoch 12/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6481 - accuracy: 0.2222\n",
      "Epoch 13/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6048 - accuracy: 0.2308\n",
      "Epoch 14/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6411 - accuracy: 0.2735\n",
      "Epoch 15/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5558 - accuracy: 0.2393\n",
      "Epoch 16/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.6107 - accuracy: 0.3333\n",
      "Epoch 17/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6149 - accuracy: 0.2991\n",
      "Epoch 18/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6320 - accuracy: 0.2650\n",
      "Epoch 19/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.6484 - accuracy: 0.2308\n",
      "Epoch 20/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5987 - accuracy: 0.2222\n",
      "Epoch 21/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.6553 - accuracy: 0.2308\n",
      "Epoch 22/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6366 - accuracy: 0.2222\n",
      "Epoch 23/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6116 - accuracy: 0.2222\n",
      "Epoch 24/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5966 - accuracy: 0.2479\n",
      "Epoch 25/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.6012 - accuracy: 0.2222\n",
      "Epoch 26/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.5949 - accuracy: 0.2222\n",
      "Epoch 27/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5983 - accuracy: 0.2735\n",
      "Epoch 28/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5969 - accuracy: 0.2650\n",
      "Epoch 29/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5730 - accuracy: 0.2735\n",
      "Epoch 30/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5506 - accuracy: 0.3248\n",
      "Epoch 31/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5713 - accuracy: 0.2821\n",
      "Epoch 32/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5543 - accuracy: 0.2564\n",
      "Epoch 33/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5405 - accuracy: 0.3162\n",
      "Epoch 34/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5881 - accuracy: 0.2308\n",
      "Epoch 35/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5469 - accuracy: 0.3077\n",
      "Epoch 36/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5526 - accuracy: 0.2821\n",
      "Epoch 37/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5669 - accuracy: 0.2479\n",
      "Epoch 38/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.4799 - accuracy: 0.2735\n",
      "Epoch 39/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5636 - accuracy: 0.2393\n",
      "Epoch 40/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5594 - accuracy: 0.2479\n",
      "Epoch 41/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5455 - accuracy: 0.2564\n",
      "Epoch 42/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5513 - accuracy: 0.2564\n",
      "Epoch 43/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5209 - accuracy: 0.3590\n",
      "Epoch 44/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.5146 - accuracy: 0.3162\n",
      "Epoch 45/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.6011 - accuracy: 0.2479\n",
      "Epoch 46/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.5170 - accuracy: 0.3248\n",
      "Epoch 47/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5580 - accuracy: 0.3162\n",
      "Epoch 48/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4846 - accuracy: 0.3333\n",
      "Epoch 49/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.4882 - accuracy: 0.3590\n",
      "Epoch 50/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4767 - accuracy: 0.3590\n",
      "Epoch 51/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5749 - accuracy: 0.2479\n",
      "Epoch 52/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.5782 - accuracy: 0.2137\n",
      "Epoch 53/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.5029 - accuracy: 0.2991\n",
      "Epoch 54/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5118 - accuracy: 0.3419\n",
      "Epoch 55/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4981 - accuracy: 0.2906\n",
      "Epoch 56/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4416 - accuracy: 0.3761\n",
      "Epoch 57/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5117 - accuracy: 0.3761\n",
      "Epoch 58/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4651 - accuracy: 0.3675\n",
      "Epoch 59/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.6014 - accuracy: 0.2735\n",
      "Epoch 60/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4435 - accuracy: 0.3932\n",
      "Epoch 61/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5327 - accuracy: 0.3248\n",
      "Epoch 62/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.5228 - accuracy: 0.3333\n",
      "Epoch 63/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3884 - accuracy: 0.3932\n",
      "Epoch 64/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4831 - accuracy: 0.3419\n",
      "Epoch 65/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4901 - accuracy: 0.3162\n",
      "Epoch 66/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.5128 - accuracy: 0.3419\n",
      "Epoch 67/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4464 - accuracy: 0.3846\n",
      "Epoch 68/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4974 - accuracy: 0.3419\n",
      "Epoch 69/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4620 - accuracy: 0.3419\n",
      "Epoch 70/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4376 - accuracy: 0.4103\n",
      "Epoch 71/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4517 - accuracy: 0.3333\n",
      "Epoch 72/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4468 - accuracy: 0.3419\n",
      "Epoch 73/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4813 - accuracy: 0.2650\n",
      "Epoch 74/1000\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.4533 - accuracy: 0.33 - 0s 51us/step - loss: 1.4688 - accuracy: 0.3248\n",
      "Epoch 75/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4585 - accuracy: 0.4017\n",
      "Epoch 76/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4551 - accuracy: 0.2991\n",
      "Epoch 77/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3831 - accuracy: 0.4615\n",
      "Epoch 78/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4659 - accuracy: 0.3162\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 1.4327 - accuracy: 0.3590\n",
      "Epoch 80/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3981 - accuracy: 0.4017\n",
      "Epoch 81/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4414 - accuracy: 0.3504\n",
      "Epoch 82/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4615 - accuracy: 0.3761\n",
      "Epoch 83/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4026 - accuracy: 0.4359\n",
      "Epoch 84/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4371 - accuracy: 0.4103\n",
      "Epoch 85/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4070 - accuracy: 0.4359\n",
      "Epoch 86/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4194 - accuracy: 0.3419\n",
      "Epoch 87/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4330 - accuracy: 0.4103\n",
      "Epoch 88/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3910 - accuracy: 0.4103\n",
      "Epoch 89/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4031 - accuracy: 0.4017\n",
      "Epoch 90/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4295 - accuracy: 0.3419\n",
      "Epoch 91/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3265 - accuracy: 0.4872\n",
      "Epoch 92/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.3719 - accuracy: 0.4530\n",
      "Epoch 93/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3273 - accuracy: 0.4701\n",
      "Epoch 94/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4849 - accuracy: 0.3504\n",
      "Epoch 95/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4058 - accuracy: 0.3846\n",
      "Epoch 96/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4120 - accuracy: 0.2991\n",
      "Epoch 97/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.4494 - accuracy: 0.3333\n",
      "Epoch 98/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3091 - accuracy: 0.4444\n",
      "Epoch 99/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3748 - accuracy: 0.3675\n",
      "Epoch 100/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3731 - accuracy: 0.3846\n",
      "Epoch 101/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3420 - accuracy: 0.4017\n",
      "Epoch 102/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.4036 - accuracy: 0.3590\n",
      "Epoch 103/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.4169 - accuracy: 0.3248\n",
      "Epoch 104/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3380 - accuracy: 0.3846\n",
      "Epoch 105/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3965 - accuracy: 0.3504\n",
      "Epoch 106/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3476 - accuracy: 0.4444\n",
      "Epoch 107/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3675 - accuracy: 0.4103\n",
      "Epoch 108/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3484 - accuracy: 0.3590\n",
      "Epoch 109/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3984 - accuracy: 0.4359\n",
      "Epoch 110/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3219 - accuracy: 0.4786\n",
      "Epoch 111/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3456 - accuracy: 0.4701\n",
      "Epoch 112/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3921 - accuracy: 0.3162\n",
      "Epoch 113/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3726 - accuracy: 0.4615\n",
      "Epoch 114/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3342 - accuracy: 0.4274\n",
      "Epoch 115/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3569 - accuracy: 0.4103\n",
      "Epoch 116/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3388 - accuracy: 0.4017\n",
      "Epoch 117/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3258 - accuracy: 0.3846\n",
      "Epoch 118/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3412 - accuracy: 0.3846\n",
      "Epoch 119/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3605 - accuracy: 0.3675\n",
      "Epoch 120/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3462 - accuracy: 0.4444\n",
      "Epoch 121/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3115 - accuracy: 0.4444\n",
      "Epoch 122/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3835 - accuracy: 0.3419\n",
      "Epoch 123/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.3477 - accuracy: 0.4188\n",
      "Epoch 124/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.3073 - accuracy: 0.4872\n",
      "Epoch 125/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3032 - accuracy: 0.4188\n",
      "Epoch 126/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3525 - accuracy: 0.4017\n",
      "Epoch 127/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3240 - accuracy: 0.3675\n",
      "Epoch 128/1000\n",
      "117/117 [==============================] - 0s 196us/step - loss: 1.2492 - accuracy: 0.4530\n",
      "Epoch 129/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3733 - accuracy: 0.3504\n",
      "Epoch 130/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3223 - accuracy: 0.3932\n",
      "Epoch 131/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3368 - accuracy: 0.3761\n",
      "Epoch 132/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2680 - accuracy: 0.3932\n",
      "Epoch 133/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.2215 - accuracy: 0.5043\n",
      "Epoch 134/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2924 - accuracy: 0.4444\n",
      "Epoch 135/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2855 - accuracy: 0.4274\n",
      "Epoch 136/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2846 - accuracy: 0.3761\n",
      "Epoch 137/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3182 - accuracy: 0.4444\n",
      "Epoch 138/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2188 - accuracy: 0.4786\n",
      "Epoch 139/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3102 - accuracy: 0.4274\n",
      "Epoch 140/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3321 - accuracy: 0.4103\n",
      "Epoch 141/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3236 - accuracy: 0.4017\n",
      "Epoch 142/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3373 - accuracy: 0.4017\n",
      "Epoch 143/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3087 - accuracy: 0.3419\n",
      "Epoch 144/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2319 - accuracy: 0.5043\n",
      "Epoch 145/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3169 - accuracy: 0.3761\n",
      "Epoch 146/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.3439 - accuracy: 0.4103\n",
      "Epoch 147/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3069 - accuracy: 0.4274\n",
      "Epoch 148/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2270 - accuracy: 0.4786\n",
      "Epoch 149/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.3167 - accuracy: 0.3675\n",
      "Epoch 150/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2926 - accuracy: 0.3932\n",
      "Epoch 151/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2671 - accuracy: 0.4103\n",
      "Epoch 152/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2864 - accuracy: 0.4188\n",
      "Epoch 153/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2978 - accuracy: 0.3846\n",
      "Epoch 154/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2638 - accuracy: 0.4359\n",
      "Epoch 155/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2295 - accuracy: 0.4615\n",
      "Epoch 156/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2250 - accuracy: 0.4017\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 1.2383 - accuracy: 0.4188\n",
      "Epoch 158/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2664 - accuracy: 0.4359\n",
      "Epoch 159/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2177 - accuracy: 0.4530\n",
      "Epoch 160/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2891 - accuracy: 0.3846\n",
      "Epoch 161/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2508 - accuracy: 0.4701\n",
      "Epoch 162/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2018 - accuracy: 0.4701\n",
      "Epoch 163/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.2792 - accuracy: 0.4444\n",
      "Epoch 164/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2390 - accuracy: 0.4359\n",
      "Epoch 165/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1964 - accuracy: 0.4615\n",
      "Epoch 166/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2384 - accuracy: 0.3761\n",
      "Epoch 167/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2296 - accuracy: 0.4957\n",
      "Epoch 168/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2386 - accuracy: 0.4274\n",
      "Epoch 169/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2582 - accuracy: 0.4444\n",
      "Epoch 170/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2208 - accuracy: 0.4188\n",
      "Epoch 171/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2261 - accuracy: 0.4786\n",
      "Epoch 172/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2399 - accuracy: 0.4274\n",
      "Epoch 173/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2642 - accuracy: 0.3932\n",
      "Epoch 174/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.3060 - accuracy: 0.3333\n",
      "Epoch 175/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.2399 - accuracy: 0.4359\n",
      "Epoch 176/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2353 - accuracy: 0.4872\n",
      "Epoch 177/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2684 - accuracy: 0.3761\n",
      "Epoch 178/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1755 - accuracy: 0.5214\n",
      "Epoch 179/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2248 - accuracy: 0.4188\n",
      "Epoch 180/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2414 - accuracy: 0.4786\n",
      "Epoch 181/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2437 - accuracy: 0.4274\n",
      "Epoch 182/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1921 - accuracy: 0.4188\n",
      "Epoch 183/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2622 - accuracy: 0.4188\n",
      "Epoch 184/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2025 - accuracy: 0.4530\n",
      "Epoch 185/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2526 - accuracy: 0.4786\n",
      "Epoch 186/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.2439 - accuracy: 0.4957\n",
      "Epoch 187/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2074 - accuracy: 0.5470\n",
      "Epoch 188/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2145 - accuracy: 0.4615\n",
      "Epoch 189/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2159 - accuracy: 0.4786\n",
      "Epoch 190/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2453 - accuracy: 0.4359\n",
      "Epoch 191/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1978 - accuracy: 0.4444\n",
      "Epoch 192/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1926 - accuracy: 0.4444\n",
      "Epoch 193/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2158 - accuracy: 0.4188\n",
      "Epoch 194/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2153 - accuracy: 0.4615\n",
      "Epoch 195/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1747 - accuracy: 0.5214\n",
      "Epoch 196/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1889 - accuracy: 0.4872\n",
      "Epoch 197/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2255 - accuracy: 0.4188\n",
      "Epoch 198/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1968 - accuracy: 0.4274\n",
      "Epoch 199/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2222 - accuracy: 0.4444\n",
      "Epoch 200/1000\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1479 - accuracy: 0.40 - 0s 51us/step - loss: 1.1925 - accuracy: 0.4188\n",
      "Epoch 201/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2053 - accuracy: 0.4188\n",
      "Epoch 202/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2329 - accuracy: 0.4017\n",
      "Epoch 203/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2184 - accuracy: 0.4274\n",
      "Epoch 204/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1952 - accuracy: 0.4274\n",
      "Epoch 205/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2324 - accuracy: 0.4274\n",
      "Epoch 206/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1492 - accuracy: 0.4444\n",
      "Epoch 207/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1981 - accuracy: 0.4615\n",
      "Epoch 208/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2379 - accuracy: 0.4188\n",
      "Epoch 209/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2609 - accuracy: 0.4530\n",
      "Epoch 210/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1301 - accuracy: 0.5214\n",
      "Epoch 211/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1925 - accuracy: 0.4615\n",
      "Epoch 212/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2148 - accuracy: 0.4359\n",
      "Epoch 213/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2400 - accuracy: 0.4957\n",
      "Epoch 214/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2062 - accuracy: 0.4615\n",
      "Epoch 215/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2096 - accuracy: 0.4444\n",
      "Epoch 216/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2040 - accuracy: 0.4444\n",
      "Epoch 217/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1275 - accuracy: 0.5726\n",
      "Epoch 218/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2058 - accuracy: 0.4444\n",
      "Epoch 219/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1154 - accuracy: 0.5043\n",
      "Epoch 220/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2225 - accuracy: 0.4274\n",
      "Epoch 221/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1666 - accuracy: 0.5128\n",
      "Epoch 222/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2062 - accuracy: 0.4872\n",
      "Epoch 223/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1823 - accuracy: 0.4444\n",
      "Epoch 224/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2582 - accuracy: 0.4359\n",
      "Epoch 225/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1793 - accuracy: 0.4359\n",
      "Epoch 226/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2676 - accuracy: 0.3419\n",
      "Epoch 227/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1242 - accuracy: 0.5043\n",
      "Epoch 228/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1753 - accuracy: 0.4274\n",
      "Epoch 229/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2213 - accuracy: 0.4017\n",
      "Epoch 230/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1485 - accuracy: 0.4615\n",
      "Epoch 231/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2187 - accuracy: 0.4359\n",
      "Epoch 232/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1727 - accuracy: 0.4615\n",
      "Epoch 233/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1129 - accuracy: 0.5128\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 1.1632 - accuracy: 0.4359\n",
      "Epoch 235/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1688 - accuracy: 0.4530\n",
      "Epoch 236/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1151 - accuracy: 0.4786\n",
      "Epoch 237/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1975 - accuracy: 0.4615\n",
      "Epoch 238/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1351 - accuracy: 0.4444\n",
      "Epoch 239/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1210 - accuracy: 0.4957\n",
      "Epoch 240/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.2075 - accuracy: 0.3932\n",
      "Epoch 241/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1914 - accuracy: 0.4872\n",
      "Epoch 242/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.2001 - accuracy: 0.4444\n",
      "Epoch 243/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1725 - accuracy: 0.4103\n",
      "Epoch 244/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1824 - accuracy: 0.4872\n",
      "Epoch 245/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1120 - accuracy: 0.5470\n",
      "Epoch 246/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1041 - accuracy: 0.4957\n",
      "Epoch 247/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1420 - accuracy: 0.4786\n",
      "Epoch 248/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1547 - accuracy: 0.4957\n",
      "Epoch 249/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1490 - accuracy: 0.4359\n",
      "Epoch 250/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2191 - accuracy: 0.4615\n",
      "Epoch 251/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1673 - accuracy: 0.4786\n",
      "Epoch 252/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.1302 - accuracy: 0.4786\n",
      "Epoch 253/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1323 - accuracy: 0.5299\n",
      "Epoch 254/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2062 - accuracy: 0.4530\n",
      "Epoch 255/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1378 - accuracy: 0.4274\n",
      "Epoch 256/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1446 - accuracy: 0.4359\n",
      "Epoch 257/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1593 - accuracy: 0.4274\n",
      "Epoch 258/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1704 - accuracy: 0.4957\n",
      "Epoch 259/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1498 - accuracy: 0.5128\n",
      "Epoch 260/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1250 - accuracy: 0.4615\n",
      "Epoch 261/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1136 - accuracy: 0.5556\n",
      "Epoch 262/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1690 - accuracy: 0.4872\n",
      "Epoch 263/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1787 - accuracy: 0.4786\n",
      "Epoch 264/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1469 - accuracy: 0.4957\n",
      "Epoch 265/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1449 - accuracy: 0.4359\n",
      "Epoch 266/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0691 - accuracy: 0.4957\n",
      "Epoch 267/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1454 - accuracy: 0.5214\n",
      "Epoch 268/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1435 - accuracy: 0.4786\n",
      "Epoch 269/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1323 - accuracy: 0.5214\n",
      "Epoch 270/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1729 - accuracy: 0.4701\n",
      "Epoch 271/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1767 - accuracy: 0.4530\n",
      "Epoch 272/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1927 - accuracy: 0.4872\n",
      "Epoch 273/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1567 - accuracy: 0.4872\n",
      "Epoch 274/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1250 - accuracy: 0.5299\n",
      "Epoch 275/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1191 - accuracy: 0.4786\n",
      "Epoch 276/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1171 - accuracy: 0.5128\n",
      "Epoch 277/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1219 - accuracy: 0.5043\n",
      "Epoch 278/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0661 - accuracy: 0.5299\n",
      "Epoch 279/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1049 - accuracy: 0.4359\n",
      "Epoch 280/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1651 - accuracy: 0.4615\n",
      "Epoch 281/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1344 - accuracy: 0.4274\n",
      "Epoch 282/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1457 - accuracy: 0.4957\n",
      "Epoch 283/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1454 - accuracy: 0.4615\n",
      "Epoch 284/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0752 - accuracy: 0.5385\n",
      "Epoch 285/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1159 - accuracy: 0.5128\n",
      "Epoch 286/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1740 - accuracy: 0.4701\n",
      "Epoch 287/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1202 - accuracy: 0.5470\n",
      "Epoch 288/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1173 - accuracy: 0.5043\n",
      "Epoch 289/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1817 - accuracy: 0.4274\n",
      "Epoch 290/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0818 - accuracy: 0.5128\n",
      "Epoch 291/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1325 - accuracy: 0.4786\n",
      "Epoch 292/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1226 - accuracy: 0.4957\n",
      "Epoch 293/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1052 - accuracy: 0.4872\n",
      "Epoch 294/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1101 - accuracy: 0.4786\n",
      "Epoch 295/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1051 - accuracy: 0.4872\n",
      "Epoch 296/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1484 - accuracy: 0.5043\n",
      "Epoch 297/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1777 - accuracy: 0.3590\n",
      "Epoch 298/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0904 - accuracy: 0.5812\n",
      "Epoch 299/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1378 - accuracy: 0.4615\n",
      "Epoch 300/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0957 - accuracy: 0.5299\n",
      "Epoch 301/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1056 - accuracy: 0.4957\n",
      "Epoch 302/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1141 - accuracy: 0.4872\n",
      "Epoch 303/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1359 - accuracy: 0.4872\n",
      "Epoch 304/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1616 - accuracy: 0.4530\n",
      "Epoch 305/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0944 - accuracy: 0.5214\n",
      "Epoch 306/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1203 - accuracy: 0.4957\n",
      "Epoch 307/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0658 - accuracy: 0.5128\n",
      "Epoch 308/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0941 - accuracy: 0.5214\n",
      "Epoch 309/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1107 - accuracy: 0.5641\n",
      "Epoch 310/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1418 - accuracy: 0.4530\n",
      "Epoch 311/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0924 - accuracy: 0.5385\n",
      "Epoch 312/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 1.1443 - accuracy: 0.4530\n",
      "Epoch 313/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0983 - accuracy: 0.4701\n",
      "Epoch 314/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0912 - accuracy: 0.4957\n",
      "Epoch 315/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1017 - accuracy: 0.5556\n",
      "Epoch 316/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0985 - accuracy: 0.5128\n",
      "Epoch 317/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0914 - accuracy: 0.5214\n",
      "Epoch 318/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0879 - accuracy: 0.4786\n",
      "Epoch 319/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0373 - accuracy: 0.5043\n",
      "Epoch 320/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1250 - accuracy: 0.4872\n",
      "Epoch 321/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0571 - accuracy: 0.4957\n",
      "Epoch 322/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0985 - accuracy: 0.5897\n",
      "Epoch 323/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0578 - accuracy: 0.5897\n",
      "Epoch 324/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1463 - accuracy: 0.4615\n",
      "Epoch 325/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1263 - accuracy: 0.5128\n",
      "Epoch 326/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0575 - accuracy: 0.5299\n",
      "Epoch 327/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0302 - accuracy: 0.5726\n",
      "Epoch 328/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1405 - accuracy: 0.4786\n",
      "Epoch 329/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0830 - accuracy: 0.5214\n",
      "Epoch 330/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0861 - accuracy: 0.5385\n",
      "Epoch 331/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0806 - accuracy: 0.5128\n",
      "Epoch 332/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0843 - accuracy: 0.5214\n",
      "Epoch 333/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0819 - accuracy: 0.5043\n",
      "Epoch 334/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0639 - accuracy: 0.4444\n",
      "Epoch 335/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1181 - accuracy: 0.4530\n",
      "Epoch 336/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0495 - accuracy: 0.5128\n",
      "Epoch 337/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0265 - accuracy: 0.5299\n",
      "Epoch 338/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0662 - accuracy: 0.5385\n",
      "Epoch 339/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0554 - accuracy: 0.5470\n",
      "Epoch 340/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1299 - accuracy: 0.4103\n",
      "Epoch 341/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1278 - accuracy: 0.4701\n",
      "Epoch 342/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0605 - accuracy: 0.5385\n",
      "Epoch 343/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0049 - accuracy: 0.5470\n",
      "Epoch 344/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1526 - accuracy: 0.4872\n",
      "Epoch 345/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1087 - accuracy: 0.4274\n",
      "Epoch 346/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1037 - accuracy: 0.5214\n",
      "Epoch 347/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0201 - accuracy: 0.5214\n",
      "Epoch 348/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0596 - accuracy: 0.4957\n",
      "Epoch 349/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1381 - accuracy: 0.4359\n",
      "Epoch 350/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1214 - accuracy: 0.4701\n",
      "Epoch 351/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1022 - accuracy: 0.4872\n",
      "Epoch 352/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0883 - accuracy: 0.4274\n",
      "Epoch 353/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0701 - accuracy: 0.5043\n",
      "Epoch 354/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0248 - accuracy: 0.5897\n",
      "Epoch 355/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0078 - accuracy: 0.6239\n",
      "Epoch 356/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0883 - accuracy: 0.4957\n",
      "Epoch 357/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1150 - accuracy: 0.5299\n",
      "Epoch 358/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0526 - accuracy: 0.4786\n",
      "Epoch 359/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0873 - accuracy: 0.4701\n",
      "Epoch 360/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1096 - accuracy: 0.4957\n",
      "Epoch 361/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0937 - accuracy: 0.4957\n",
      "Epoch 362/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0806 - accuracy: 0.5385\n",
      "Epoch 363/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0959 - accuracy: 0.4274\n",
      "Epoch 364/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1026 - accuracy: 0.4615\n",
      "Epoch 365/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0186 - accuracy: 0.5385\n",
      "Epoch 366/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0613 - accuracy: 0.4786\n",
      "Epoch 367/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0718 - accuracy: 0.4786\n",
      "Epoch 368/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0645 - accuracy: 0.4872\n",
      "Epoch 369/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0745 - accuracy: 0.4615\n",
      "Epoch 370/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0740 - accuracy: 0.4701\n",
      "Epoch 371/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0933 - accuracy: 0.4701\n",
      "Epoch 372/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1332 - accuracy: 0.4188\n",
      "Epoch 373/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0944 - accuracy: 0.5043\n",
      "Epoch 374/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0896 - accuracy: 0.5128\n",
      "Epoch 375/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0542 - accuracy: 0.4872\n",
      "Epoch 376/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0894 - accuracy: 0.5214\n",
      "Epoch 377/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0801 - accuracy: 0.4530\n",
      "Epoch 378/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0523 - accuracy: 0.5043\n",
      "Epoch 379/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0270 - accuracy: 0.5385\n",
      "Epoch 380/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0698 - accuracy: 0.5299\n",
      "Epoch 381/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0998 - accuracy: 0.4615\n",
      "Epoch 382/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0247 - accuracy: 0.5385\n",
      "Epoch 383/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0195 - accuracy: 0.5385\n",
      "Epoch 384/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.1614 - accuracy: 0.4530\n",
      "Epoch 385/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0577 - accuracy: 0.4786\n",
      "Epoch 386/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1104 - accuracy: 0.4872\n",
      "Epoch 387/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0373 - accuracy: 0.5470\n",
      "Epoch 388/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0822 - accuracy: 0.4274\n",
      "Epoch 389/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0127 - accuracy: 0.5641\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 1.0894 - accuracy: 0.4701\n",
      "Epoch 391/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0393 - accuracy: 0.5299\n",
      "Epoch 392/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0209 - accuracy: 0.5299\n",
      "Epoch 393/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0465 - accuracy: 0.5641\n",
      "Epoch 394/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9949 - accuracy: 0.5556\n",
      "Epoch 395/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0714 - accuracy: 0.4957\n",
      "Epoch 396/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0651 - accuracy: 0.5128\n",
      "Epoch 397/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0114 - accuracy: 0.5897\n",
      "Epoch 398/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0525 - accuracy: 0.4615\n",
      "Epoch 399/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.2300 - accuracy: 0.4274\n",
      "Epoch 400/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0754 - accuracy: 0.4188\n",
      "Epoch 401/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0958 - accuracy: 0.4615\n",
      "Epoch 402/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0350 - accuracy: 0.6068\n",
      "Epoch 403/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0961 - accuracy: 0.4701\n",
      "Epoch 404/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0517 - accuracy: 0.5299\n",
      "Epoch 405/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0402 - accuracy: 0.5128\n",
      "Epoch 406/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0279 - accuracy: 0.5214\n",
      "Epoch 407/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0886 - accuracy: 0.5128\n",
      "Epoch 408/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0677 - accuracy: 0.5556\n",
      "Epoch 409/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0339 - accuracy: 0.5726\n",
      "Epoch 410/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1009 - accuracy: 0.4957\n",
      "Epoch 411/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0747 - accuracy: 0.4786\n",
      "Epoch 412/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0800 - accuracy: 0.5726\n",
      "Epoch 413/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9868 - accuracy: 0.5726\n",
      "Epoch 414/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9826 - accuracy: 0.4957\n",
      "Epoch 415/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0577 - accuracy: 0.5128\n",
      "Epoch 416/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0237 - accuracy: 0.5812\n",
      "Epoch 417/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0627 - accuracy: 0.5128\n",
      "Epoch 418/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9845 - accuracy: 0.5470\n",
      "Epoch 419/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0353 - accuracy: 0.5385\n",
      "Epoch 420/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0720 - accuracy: 0.5214\n",
      "Epoch 421/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0717 - accuracy: 0.4872\n",
      "Epoch 422/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0844 - accuracy: 0.5299\n",
      "Epoch 423/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0620 - accuracy: 0.4872\n",
      "Epoch 424/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0107 - accuracy: 0.4957\n",
      "Epoch 425/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0716 - accuracy: 0.4530\n",
      "Epoch 426/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0649 - accuracy: 0.4957\n",
      "Epoch 427/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0346 - accuracy: 0.5214\n",
      "Epoch 428/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9969 - accuracy: 0.5299\n",
      "Epoch 429/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0392 - accuracy: 0.6068\n",
      "Epoch 430/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0678 - accuracy: 0.4786\n",
      "Epoch 431/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0055 - accuracy: 0.6068\n",
      "Epoch 432/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0455 - accuracy: 0.5385\n",
      "Epoch 433/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0789 - accuracy: 0.5385\n",
      "Epoch 434/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0001 - accuracy: 0.5641\n",
      "Epoch 435/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9938 - accuracy: 0.5641\n",
      "Epoch 436/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9651 - accuracy: 0.5641\n",
      "Epoch 437/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1143 - accuracy: 0.4530\n",
      "Epoch 438/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0403 - accuracy: 0.5983\n",
      "Epoch 439/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0304 - accuracy: 0.4872\n",
      "Epoch 440/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0573 - accuracy: 0.5128\n",
      "Epoch 441/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 1.0601 - accuracy: 0.5385\n",
      "Epoch 442/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0112 - accuracy: 0.5299\n",
      "Epoch 443/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9694 - accuracy: 0.5726\n",
      "Epoch 444/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0901 - accuracy: 0.5299\n",
      "Epoch 445/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0173 - accuracy: 0.4872\n",
      "Epoch 446/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0385 - accuracy: 0.5043\n",
      "Epoch 447/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0136 - accuracy: 0.5214\n",
      "Epoch 448/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0283 - accuracy: 0.5043\n",
      "Epoch 449/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9970 - accuracy: 0.5556\n",
      "Epoch 450/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0433 - accuracy: 0.4872\n",
      "Epoch 451/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0476 - accuracy: 0.4957\n",
      "Epoch 452/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0357 - accuracy: 0.5812\n",
      "Epoch 453/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0776 - accuracy: 0.5128\n",
      "Epoch 454/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1004 - accuracy: 0.4786\n",
      "Epoch 455/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0187 - accuracy: 0.5128\n",
      "Epoch 456/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0518 - accuracy: 0.5470\n",
      "Epoch 457/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0237 - accuracy: 0.5299\n",
      "Epoch 458/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9853 - accuracy: 0.5128\n",
      "Epoch 459/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.1077 - accuracy: 0.4786\n",
      "Epoch 460/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0303 - accuracy: 0.4786\n",
      "Epoch 461/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9748 - accuracy: 0.5128\n",
      "Epoch 462/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0599 - accuracy: 0.5470\n",
      "Epoch 463/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0002 - accuracy: 0.5556\n",
      "Epoch 464/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0137 - accuracy: 0.5385\n",
      "Epoch 465/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.1225 - accuracy: 0.5128\n",
      "Epoch 466/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0275 - accuracy: 0.5043\n",
      "Epoch 467/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0210 - accuracy: 0.4957\n",
      "Epoch 468/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 68us/step - loss: 0.9964 - accuracy: 0.5128\n",
      "Epoch 469/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0368 - accuracy: 0.5641\n",
      "Epoch 470/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0187 - accuracy: 0.5385\n",
      "Epoch 471/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0139 - accuracy: 0.5726\n",
      "Epoch 472/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0584 - accuracy: 0.5299\n",
      "Epoch 473/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0682 - accuracy: 0.4530\n",
      "Epoch 474/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0113 - accuracy: 0.5214\n",
      "Epoch 475/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0404 - accuracy: 0.4786\n",
      "Epoch 476/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0683 - accuracy: 0.5385\n",
      "Epoch 477/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0020 - accuracy: 0.5641\n",
      "Epoch 478/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0480 - accuracy: 0.5043\n",
      "Epoch 479/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0702 - accuracy: 0.5043\n",
      "Epoch 480/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0332 - accuracy: 0.5299\n",
      "Epoch 481/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0190 - accuracy: 0.5299\n",
      "Epoch 482/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9883 - accuracy: 0.5726\n",
      "Epoch 483/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0055 - accuracy: 0.5128\n",
      "Epoch 484/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0275 - accuracy: 0.5043\n",
      "Epoch 485/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0089 - accuracy: 0.5726\n",
      "Epoch 486/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9806 - accuracy: 0.5812\n",
      "Epoch 487/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0227 - accuracy: 0.5470\n",
      "Epoch 488/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0133 - accuracy: 0.5299\n",
      "Epoch 489/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9299 - accuracy: 0.5897\n",
      "Epoch 490/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9778 - accuracy: 0.5983\n",
      "Epoch 491/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9979 - accuracy: 0.4872\n",
      "Epoch 492/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9367 - accuracy: 0.6581\n",
      "Epoch 493/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9965 - accuracy: 0.4701\n",
      "Epoch 494/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0164 - accuracy: 0.4872\n",
      "Epoch 495/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0682 - accuracy: 0.4872\n",
      "Epoch 496/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0366 - accuracy: 0.5128\n",
      "Epoch 497/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9661 - accuracy: 0.5897\n",
      "Epoch 498/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0302 - accuracy: 0.5043\n",
      "Epoch 499/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0262 - accuracy: 0.5043\n",
      "Epoch 500/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9866 - accuracy: 0.5128\n",
      "Epoch 501/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0120 - accuracy: 0.6068\n",
      "Epoch 502/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9905 - accuracy: 0.5812\n",
      "Epoch 503/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0086 - accuracy: 0.5043\n",
      "Epoch 504/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0004 - accuracy: 0.5470\n",
      "Epoch 505/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9734 - accuracy: 0.5983\n",
      "Epoch 506/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0029 - accuracy: 0.5470\n",
      "Epoch 507/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9702 - accuracy: 0.5385\n",
      "Epoch 508/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0337 - accuracy: 0.5897\n",
      "Epoch 509/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0651 - accuracy: 0.4274\n",
      "Epoch 510/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9870 - accuracy: 0.5641\n",
      "Epoch 511/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0619 - accuracy: 0.5043\n",
      "Epoch 512/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0961 - accuracy: 0.5128\n",
      "Epoch 513/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9903 - accuracy: 0.5214\n",
      "Epoch 514/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9690 - accuracy: 0.5556\n",
      "Epoch 515/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9962 - accuracy: 0.5641\n",
      "Epoch 516/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9780 - accuracy: 0.5812\n",
      "Epoch 517/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0072 - accuracy: 0.5043\n",
      "Epoch 518/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0409 - accuracy: 0.5726\n",
      "Epoch 519/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0094 - accuracy: 0.4957\n",
      "Epoch 520/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9991 - accuracy: 0.5128\n",
      "Epoch 521/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0197 - accuracy: 0.5470\n",
      "Epoch 522/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9873 - accuracy: 0.5470\n",
      "Epoch 523/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0122 - accuracy: 0.5043\n",
      "Epoch 524/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0691 - accuracy: 0.4701\n",
      "Epoch 525/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9922 - accuracy: 0.5128\n",
      "Epoch 526/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9353 - accuracy: 0.5983\n",
      "Epoch 527/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9993 - accuracy: 0.4786\n",
      "Epoch 528/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9950 - accuracy: 0.5470\n",
      "Epoch 529/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9640 - accuracy: 0.5385\n",
      "Epoch 530/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9971 - accuracy: 0.5128\n",
      "Epoch 531/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0402 - accuracy: 0.4701\n",
      "Epoch 532/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0067 - accuracy: 0.5897\n",
      "Epoch 533/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0279 - accuracy: 0.5470\n",
      "Epoch 534/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0045 - accuracy: 0.5470\n",
      "Epoch 535/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9976 - accuracy: 0.5812\n",
      "Epoch 536/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0345 - accuracy: 0.5385\n",
      "Epoch 537/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0418 - accuracy: 0.4786\n",
      "Epoch 538/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9803 - accuracy: 0.5897\n",
      "Epoch 539/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0434 - accuracy: 0.5128\n",
      "Epoch 540/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0024 - accuracy: 0.5299\n",
      "Epoch 541/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9624 - accuracy: 0.5812\n",
      "Epoch 542/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0482 - accuracy: 0.5214\n",
      "Epoch 543/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0149 - accuracy: 0.5299\n",
      "Epoch 544/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9832 - accuracy: 0.5128\n",
      "Epoch 545/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9839 - accuracy: 0.6068\n",
      "Epoch 546/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 1.0260 - accuracy: 0.4957\n",
      "Epoch 547/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0332 - accuracy: 0.4786\n",
      "Epoch 548/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9725 - accuracy: 0.5726\n",
      "Epoch 549/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9632 - accuracy: 0.5726\n",
      "Epoch 550/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0117 - accuracy: 0.5299\n",
      "Epoch 551/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9793 - accuracy: 0.5641\n",
      "Epoch 552/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0205 - accuracy: 0.5897\n",
      "Epoch 553/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0104 - accuracy: 0.4957\n",
      "Epoch 554/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0020 - accuracy: 0.5299\n",
      "Epoch 555/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9819 - accuracy: 0.5299\n",
      "Epoch 556/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9945 - accuracy: 0.5812\n",
      "Epoch 557/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9502 - accuracy: 0.6068\n",
      "Epoch 558/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9296 - accuracy: 0.5726\n",
      "Epoch 559/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9534 - accuracy: 0.6325\n",
      "Epoch 560/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0288 - accuracy: 0.4786\n",
      "Epoch 561/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9434 - accuracy: 0.5556\n",
      "Epoch 562/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0188 - accuracy: 0.5897\n",
      "Epoch 563/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9746 - accuracy: 0.5128\n",
      "Epoch 564/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9812 - accuracy: 0.5128\n",
      "Epoch 565/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0336 - accuracy: 0.5470\n",
      "Epoch 566/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0099 - accuracy: 0.5470\n",
      "Epoch 567/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9826 - accuracy: 0.6068\n",
      "Epoch 568/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0471 - accuracy: 0.5043\n",
      "Epoch 569/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9397 - accuracy: 0.5556\n",
      "Epoch 570/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9679 - accuracy: 0.5726\n",
      "Epoch 571/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0180 - accuracy: 0.5214\n",
      "Epoch 572/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9839 - accuracy: 0.6068\n",
      "Epoch 573/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9909 - accuracy: 0.5470\n",
      "Epoch 574/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0757 - accuracy: 0.5641\n",
      "Epoch 575/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9851 - accuracy: 0.5812\n",
      "Epoch 576/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0284 - accuracy: 0.5214\n",
      "Epoch 577/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9750 - accuracy: 0.4786\n",
      "Epoch 578/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0384 - accuracy: 0.4872\n",
      "Epoch 579/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9395 - accuracy: 0.6154\n",
      "Epoch 580/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9859 - accuracy: 0.5470\n",
      "Epoch 581/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0140 - accuracy: 0.5385\n",
      "Epoch 582/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9948 - accuracy: 0.5556\n",
      "Epoch 583/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9997 - accuracy: 0.5726\n",
      "Epoch 584/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9931 - accuracy: 0.4786\n",
      "Epoch 585/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9376 - accuracy: 0.6154\n",
      "Epoch 586/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9664 - accuracy: 0.5128\n",
      "Epoch 587/1000\n",
      "117/117 [==============================] - ETA: 0s - loss: 1.1268 - accuracy: 0.43 - 0s 68us/step - loss: 1.0887 - accuracy: 0.4103\n",
      "Epoch 588/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9810 - accuracy: 0.6068\n",
      "Epoch 589/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0254 - accuracy: 0.5214\n",
      "Epoch 590/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9710 - accuracy: 0.5897\n",
      "Epoch 591/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9562 - accuracy: 0.5897\n",
      "Epoch 592/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9592 - accuracy: 0.6239\n",
      "Epoch 593/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9742 - accuracy: 0.6068\n",
      "Epoch 594/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9914 - accuracy: 0.5214\n",
      "Epoch 595/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0037 - accuracy: 0.4701\n",
      "Epoch 596/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9985 - accuracy: 0.5385\n",
      "Epoch 597/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9998 - accuracy: 0.5299\n",
      "Epoch 598/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0029 - accuracy: 0.5385\n",
      "Epoch 599/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0311 - accuracy: 0.5043\n",
      "Epoch 600/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0053 - accuracy: 0.5385\n",
      "Epoch 601/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9494 - accuracy: 0.5812\n",
      "Epoch 602/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0258 - accuracy: 0.4957\n",
      "Epoch 603/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9375 - accuracy: 0.6154\n",
      "Epoch 604/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9955 - accuracy: 0.4957\n",
      "Epoch 605/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0169 - accuracy: 0.5299\n",
      "Epoch 606/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9927 - accuracy: 0.5385\n",
      "Epoch 607/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9229 - accuracy: 0.5385\n",
      "Epoch 608/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9447 - accuracy: 0.5812\n",
      "Epoch 609/1000\n",
      "117/117 [==============================] - 0s 102us/step - loss: 0.9942 - accuracy: 0.5556\n",
      "Epoch 610/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9737 - accuracy: 0.5214\n",
      "Epoch 611/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9129 - accuracy: 0.5385\n",
      "Epoch 612/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9608 - accuracy: 0.5897\n",
      "Epoch 613/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9037 - accuracy: 0.5641\n",
      "Epoch 614/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9982 - accuracy: 0.5385\n",
      "Epoch 615/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9863 - accuracy: 0.5214\n",
      "Epoch 616/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0233 - accuracy: 0.5128\n",
      "Epoch 617/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9253 - accuracy: 0.5641\n",
      "Epoch 618/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9536 - accuracy: 0.5641\n",
      "Epoch 619/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8854 - accuracy: 0.5983\n",
      "Epoch 620/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9753 - accuracy: 0.5043\n",
      "Epoch 621/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9215 - accuracy: 0.5470\n",
      "Epoch 622/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9749 - accuracy: 0.5641\n",
      "Epoch 623/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 0.9881 - accuracy: 0.5385\n",
      "Epoch 624/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0176 - accuracy: 0.5641\n",
      "Epoch 625/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9886 - accuracy: 0.5812\n",
      "Epoch 626/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9717 - accuracy: 0.5726\n",
      "Epoch 627/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9786 - accuracy: 0.5299\n",
      "Epoch 628/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9639 - accuracy: 0.5470\n",
      "Epoch 629/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0062 - accuracy: 0.5128\n",
      "Epoch 630/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9820 - accuracy: 0.5556\n",
      "Epoch 631/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9926 - accuracy: 0.5641\n",
      "Epoch 632/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0049 - accuracy: 0.5726\n",
      "Epoch 633/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9921 - accuracy: 0.6239\n",
      "Epoch 634/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9552 - accuracy: 0.5556\n",
      "Epoch 635/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9617 - accuracy: 0.5043\n",
      "Epoch 636/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0196 - accuracy: 0.5726\n",
      "Epoch 637/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0275 - accuracy: 0.5385\n",
      "Epoch 638/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0215 - accuracy: 0.5128\n",
      "Epoch 639/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0030 - accuracy: 0.5299\n",
      "Epoch 640/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0155 - accuracy: 0.5128\n",
      "Epoch 641/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9362 - accuracy: 0.5385\n",
      "Epoch 642/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9508 - accuracy: 0.5299\n",
      "Epoch 643/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9201 - accuracy: 0.6154\n",
      "Epoch 644/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9538 - accuracy: 0.5812\n",
      "Epoch 645/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0062 - accuracy: 0.4957\n",
      "Epoch 646/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9197 - accuracy: 0.6581\n",
      "Epoch 647/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8951 - accuracy: 0.6068\n",
      "Epoch 648/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9171 - accuracy: 0.5556\n",
      "Epoch 649/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9410 - accuracy: 0.6068\n",
      "Epoch 650/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9521 - accuracy: 0.6325\n",
      "Epoch 651/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0035 - accuracy: 0.5385\n",
      "Epoch 652/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 1.0156 - accuracy: 0.4957\n",
      "Epoch 653/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9243 - accuracy: 0.5897\n",
      "Epoch 654/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9295 - accuracy: 0.5641\n",
      "Epoch 655/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9772 - accuracy: 0.5299\n",
      "Epoch 656/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9917 - accuracy: 0.5385\n",
      "Epoch 657/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9818 - accuracy: 0.5812\n",
      "Epoch 658/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9288 - accuracy: 0.5385\n",
      "Epoch 659/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 1.0112 - accuracy: 0.5128\n",
      "Epoch 660/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9415 - accuracy: 0.5983\n",
      "Epoch 661/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9654 - accuracy: 0.5812\n",
      "Epoch 662/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9959 - accuracy: 0.5470\n",
      "Epoch 663/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9097 - accuracy: 0.5128\n",
      "Epoch 664/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0348 - accuracy: 0.5385\n",
      "Epoch 665/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0046 - accuracy: 0.5043\n",
      "Epoch 666/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9305 - accuracy: 0.5726\n",
      "Epoch 667/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9034 - accuracy: 0.6239\n",
      "Epoch 668/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9105 - accuracy: 0.5812\n",
      "Epoch 669/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9965 - accuracy: 0.5726\n",
      "Epoch 670/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9696 - accuracy: 0.5214\n",
      "Epoch 671/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9736 - accuracy: 0.5812\n",
      "Epoch 672/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9856 - accuracy: 0.5556\n",
      "Epoch 673/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9229 - accuracy: 0.5470\n",
      "Epoch 674/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0044 - accuracy: 0.5556\n",
      "Epoch 675/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0025 - accuracy: 0.5556\n",
      "Epoch 676/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9389 - accuracy: 0.5043\n",
      "Epoch 677/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8956 - accuracy: 0.5897\n",
      "Epoch 678/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9550 - accuracy: 0.6154\n",
      "Epoch 679/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9519 - accuracy: 0.5043\n",
      "Epoch 680/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9746 - accuracy: 0.5641\n",
      "Epoch 681/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9471 - accuracy: 0.5641\n",
      "Epoch 682/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0432 - accuracy: 0.4957\n",
      "Epoch 683/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9291 - accuracy: 0.5556\n",
      "Epoch 684/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9272 - accuracy: 0.5299\n",
      "Epoch 685/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9581 - accuracy: 0.4872\n",
      "Epoch 686/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0047 - accuracy: 0.5641\n",
      "Epoch 687/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9645 - accuracy: 0.5641\n",
      "Epoch 688/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9741 - accuracy: 0.5385\n",
      "Epoch 689/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9274 - accuracy: 0.5983\n",
      "Epoch 690/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9788 - accuracy: 0.5128\n",
      "Epoch 691/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9949 - accuracy: 0.5641\n",
      "Epoch 692/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9206 - accuracy: 0.6154\n",
      "Epoch 693/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9863 - accuracy: 0.5128\n",
      "Epoch 694/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9615 - accuracy: 0.5214\n",
      "Epoch 695/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9542 - accuracy: 0.5556\n",
      "Epoch 696/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9214 - accuracy: 0.5299\n",
      "Epoch 697/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9466 - accuracy: 0.5726\n",
      "Epoch 698/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0173 - accuracy: 0.5385\n",
      "Epoch 699/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 1.0767 - accuracy: 0.4530\n",
      "Epoch 700/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0763 - accuracy: 0.4530\n",
      "Epoch 701/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 0.9833 - accuracy: 0.5128\n",
      "Epoch 702/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9317 - accuracy: 0.5043\n",
      "Epoch 703/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9122 - accuracy: 0.6068\n",
      "Epoch 704/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9903 - accuracy: 0.5385\n",
      "Epoch 705/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9466 - accuracy: 0.5641\n",
      "Epoch 706/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9560 - accuracy: 0.5470\n",
      "Epoch 707/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0321 - accuracy: 0.5385\n",
      "Epoch 708/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9363 - accuracy: 0.5641\n",
      "Epoch 709/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9662 - accuracy: 0.5983\n",
      "Epoch 710/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9165 - accuracy: 0.5983\n",
      "Epoch 711/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8903 - accuracy: 0.6239\n",
      "Epoch 712/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9869 - accuracy: 0.5556\n",
      "Epoch 713/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9412 - accuracy: 0.5470\n",
      "Epoch 714/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9544 - accuracy: 0.5214\n",
      "Epoch 715/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9327 - accuracy: 0.5812\n",
      "Epoch 716/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9110 - accuracy: 0.5214\n",
      "Epoch 717/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9663 - accuracy: 0.5470\n",
      "Epoch 718/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9663 - accuracy: 0.5470\n",
      "Epoch 719/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9820 - accuracy: 0.5299\n",
      "Epoch 720/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9247 - accuracy: 0.6239\n",
      "Epoch 721/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 1.0139 - accuracy: 0.5299\n",
      "Epoch 722/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9959 - accuracy: 0.5128\n",
      "Epoch 723/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9734 - accuracy: 0.5214\n",
      "Epoch 724/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9409 - accuracy: 0.5556\n",
      "Epoch 725/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9331 - accuracy: 0.5641\n",
      "Epoch 726/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9536 - accuracy: 0.5385\n",
      "Epoch 727/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9318 - accuracy: 0.5983\n",
      "Epoch 728/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9310 - accuracy: 0.5812\n",
      "Epoch 729/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9130 - accuracy: 0.5812\n",
      "Epoch 730/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9787 - accuracy: 0.6068\n",
      "Epoch 731/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9508 - accuracy: 0.5726\n",
      "Epoch 732/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9293 - accuracy: 0.5641\n",
      "Epoch 733/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9588 - accuracy: 0.5812\n",
      "Epoch 734/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9634 - accuracy: 0.5726\n",
      "Epoch 735/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9231 - accuracy: 0.5812\n",
      "Epoch 736/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9101 - accuracy: 0.5641\n",
      "Epoch 737/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9261 - accuracy: 0.5897\n",
      "Epoch 738/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8894 - accuracy: 0.6496\n",
      "Epoch 739/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9672 - accuracy: 0.5043\n",
      "Epoch 740/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 1.0038 - accuracy: 0.5299\n",
      "Epoch 741/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9384 - accuracy: 0.5812\n",
      "Epoch 742/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9006 - accuracy: 0.5897\n",
      "Epoch 743/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9221 - accuracy: 0.5214\n",
      "Epoch 744/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9945 - accuracy: 0.5556\n",
      "Epoch 745/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9592 - accuracy: 0.5385\n",
      "Epoch 746/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9600 - accuracy: 0.5897\n",
      "Epoch 747/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9338 - accuracy: 0.5214\n",
      "Epoch 748/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9383 - accuracy: 0.5726\n",
      "Epoch 749/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8894 - accuracy: 0.6068\n",
      "Epoch 750/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9913 - accuracy: 0.5556\n",
      "Epoch 751/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8932 - accuracy: 0.5812\n",
      "Epoch 752/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8625 - accuracy: 0.6239\n",
      "Epoch 753/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9533 - accuracy: 0.5556\n",
      "Epoch 754/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9596 - accuracy: 0.5556\n",
      "Epoch 755/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8980 - accuracy: 0.6838\n",
      "Epoch 756/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9528 - accuracy: 0.6068\n",
      "Epoch 757/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9032 - accuracy: 0.5470\n",
      "Epoch 758/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9398 - accuracy: 0.6154\n",
      "Epoch 759/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9049 - accuracy: 0.5812\n",
      "Epoch 760/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9921 - accuracy: 0.5385\n",
      "Epoch 761/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9105 - accuracy: 0.5897\n",
      "Epoch 762/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9289 - accuracy: 0.5641\n",
      "Epoch 763/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9230 - accuracy: 0.6068\n",
      "Epoch 764/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9630 - accuracy: 0.5128\n",
      "Epoch 765/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9762 - accuracy: 0.5470\n",
      "Epoch 766/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9135 - accuracy: 0.5812\n",
      "Epoch 767/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9180 - accuracy: 0.5897\n",
      "Epoch 768/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9902 - accuracy: 0.5470\n",
      "Epoch 769/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9559 - accuracy: 0.5556\n",
      "Epoch 770/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9546 - accuracy: 0.5726\n",
      "Epoch 771/1000\n",
      "117/117 [==============================] - 0s 43us/step - loss: 0.9676 - accuracy: 0.5641\n",
      "Epoch 772/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9683 - accuracy: 0.5556\n",
      "Epoch 773/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9667 - accuracy: 0.5128\n",
      "Epoch 774/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8942 - accuracy: 0.5897\n",
      "Epoch 775/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9639 - accuracy: 0.5470\n",
      "Epoch 776/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9705 - accuracy: 0.5385\n",
      "Epoch 777/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9721 - accuracy: 0.5897\n",
      "Epoch 778/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9135 - accuracy: 0.5726\n",
      "Epoch 779/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 60us/step - loss: 0.9027 - accuracy: 0.5299\n",
      "Epoch 780/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9063 - accuracy: 0.5299\n",
      "Epoch 781/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9567 - accuracy: 0.4786\n",
      "Epoch 782/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8868 - accuracy: 0.5812\n",
      "Epoch 783/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9233 - accuracy: 0.5556\n",
      "Epoch 784/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9281 - accuracy: 0.5385\n",
      "Epoch 785/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9385 - accuracy: 0.5812\n",
      "Epoch 786/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9605 - accuracy: 0.5897\n",
      "Epoch 787/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9820 - accuracy: 0.5812\n",
      "Epoch 788/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9019 - accuracy: 0.6068\n",
      "Epoch 789/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9301 - accuracy: 0.5983\n",
      "Epoch 790/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9603 - accuracy: 0.5214\n",
      "Epoch 791/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9951 - accuracy: 0.5812\n",
      "Epoch 792/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9596 - accuracy: 0.5128\n",
      "Epoch 793/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8614 - accuracy: 0.5983\n",
      "Epoch 794/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9289 - accuracy: 0.5812\n",
      "Epoch 795/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9038 - accuracy: 0.5556\n",
      "Epoch 796/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9059 - accuracy: 0.6068\n",
      "Epoch 797/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9405 - accuracy: 0.5214\n",
      "Epoch 798/1000\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.9162 - accuracy: 0.66 - 0s 60us/step - loss: 0.9276 - accuracy: 0.6496\n",
      "Epoch 799/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9134 - accuracy: 0.6239\n",
      "Epoch 800/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9095 - accuracy: 0.5726\n",
      "Epoch 801/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8784 - accuracy: 0.6325\n",
      "Epoch 802/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9510 - accuracy: 0.5043\n",
      "Epoch 803/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9341 - accuracy: 0.5299\n",
      "Epoch 804/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9346 - accuracy: 0.5983\n",
      "Epoch 805/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9118 - accuracy: 0.5470\n",
      "Epoch 806/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8652 - accuracy: 0.6068\n",
      "Epoch 807/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9603 - accuracy: 0.5556\n",
      "Epoch 808/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9009 - accuracy: 0.5556\n",
      "Epoch 809/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9102 - accuracy: 0.6325\n",
      "Epoch 810/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8988 - accuracy: 0.6068\n",
      "Epoch 811/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9575 - accuracy: 0.5726\n",
      "Epoch 812/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9042 - accuracy: 0.5812\n",
      "Epoch 813/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9804 - accuracy: 0.5556\n",
      "Epoch 814/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8789 - accuracy: 0.5897\n",
      "Epoch 815/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9136 - accuracy: 0.5812\n",
      "Epoch 816/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9657 - accuracy: 0.5641\n",
      "Epoch 817/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9650 - accuracy: 0.5726\n",
      "Epoch 818/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9477 - accuracy: 0.4701\n",
      "Epoch 819/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9033 - accuracy: 0.5641\n",
      "Epoch 820/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9868 - accuracy: 0.5214\n",
      "Epoch 821/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8999 - accuracy: 0.6154\n",
      "Epoch 822/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8330 - accuracy: 0.6496\n",
      "Epoch 823/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8400 - accuracy: 0.6154\n",
      "Epoch 824/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9125 - accuracy: 0.5897\n",
      "Epoch 825/1000\n",
      "117/117 [==============================] - ETA: 0s - loss: 0.8924 - accuracy: 0.66 - 0s 60us/step - loss: 0.9046 - accuracy: 0.6068\n",
      "Epoch 826/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9355 - accuracy: 0.6154\n",
      "Epoch 827/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9288 - accuracy: 0.5812\n",
      "Epoch 828/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9272 - accuracy: 0.5812\n",
      "Epoch 829/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8654 - accuracy: 0.5812\n",
      "Epoch 830/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9205 - accuracy: 0.5214\n",
      "Epoch 831/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8921 - accuracy: 0.6325\n",
      "Epoch 832/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9066 - accuracy: 0.5897\n",
      "Epoch 833/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9712 - accuracy: 0.6068\n",
      "Epoch 834/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9534 - accuracy: 0.6068\n",
      "Epoch 835/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8428 - accuracy: 0.6239\n",
      "Epoch 836/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9092 - accuracy: 0.5128\n",
      "Epoch 837/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9275 - accuracy: 0.4701\n",
      "Epoch 838/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8746 - accuracy: 0.5983\n",
      "Epoch 839/1000\n",
      "117/117 [==============================] - 0s 230us/step - loss: 0.8841 - accuracy: 0.6410\n",
      "Epoch 840/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8640 - accuracy: 0.6068\n",
      "Epoch 841/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8857 - accuracy: 0.5812\n",
      "Epoch 842/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 1.0179 - accuracy: 0.5128\n",
      "Epoch 843/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9464 - accuracy: 0.5726\n",
      "Epoch 844/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9428 - accuracy: 0.5299\n",
      "Epoch 845/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8827 - accuracy: 0.5812\n",
      "Epoch 846/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8712 - accuracy: 0.5812\n",
      "Epoch 847/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9027 - accuracy: 0.5812\n",
      "Epoch 848/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9079 - accuracy: 0.5470\n",
      "Epoch 849/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8752 - accuracy: 0.6068\n",
      "Epoch 850/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9737 - accuracy: 0.5470\n",
      "Epoch 851/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9326 - accuracy: 0.5470\n",
      "Epoch 852/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8928 - accuracy: 0.6410\n",
      "Epoch 853/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8837 - accuracy: 0.5983\n",
      "Epoch 854/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9257 - accuracy: 0.5726\n",
      "Epoch 855/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9515 - accuracy: 0.5641\n",
      "Epoch 856/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 51us/step - loss: 0.9023 - accuracy: 0.5726\n",
      "Epoch 857/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9037 - accuracy: 0.6410\n",
      "Epoch 858/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8857 - accuracy: 0.6496\n",
      "Epoch 859/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9715 - accuracy: 0.5726\n",
      "Epoch 860/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9490 - accuracy: 0.5812\n",
      "Epoch 861/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9486 - accuracy: 0.5812\n",
      "Epoch 862/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9569 - accuracy: 0.6068\n",
      "Epoch 863/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8834 - accuracy: 0.6068\n",
      "Epoch 864/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8762 - accuracy: 0.6239\n",
      "Epoch 865/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9639 - accuracy: 0.5214\n",
      "Epoch 866/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8577 - accuracy: 0.6496\n",
      "Epoch 867/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9116 - accuracy: 0.5897\n",
      "Epoch 868/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9251 - accuracy: 0.6239\n",
      "Epoch 869/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9313 - accuracy: 0.6410\n",
      "Epoch 870/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8950 - accuracy: 0.5812\n",
      "Epoch 871/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8409 - accuracy: 0.6496\n",
      "Epoch 872/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9946 - accuracy: 0.5385\n",
      "Epoch 873/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9033 - accuracy: 0.5726\n",
      "Epoch 874/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8880 - accuracy: 0.5897\n",
      "Epoch 875/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8574 - accuracy: 0.6752\n",
      "Epoch 876/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8476 - accuracy: 0.6068\n",
      "Epoch 877/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9465 - accuracy: 0.5385\n",
      "Epoch 878/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8580 - accuracy: 0.6154\n",
      "Epoch 879/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9234 - accuracy: 0.5897\n",
      "Epoch 880/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9239 - accuracy: 0.5556\n",
      "Epoch 881/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9700 - accuracy: 0.5043\n",
      "Epoch 882/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8638 - accuracy: 0.6068\n",
      "Epoch 883/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9423 - accuracy: 0.5641\n",
      "Epoch 884/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9349 - accuracy: 0.5128\n",
      "Epoch 885/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8915 - accuracy: 0.5983\n",
      "Epoch 886/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9384 - accuracy: 0.5641\n",
      "Epoch 887/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9496 - accuracy: 0.5641\n",
      "Epoch 888/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9572 - accuracy: 0.5641\n",
      "Epoch 889/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8900 - accuracy: 0.5812\n",
      "Epoch 890/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9370 - accuracy: 0.5556\n",
      "Epoch 891/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8540 - accuracy: 0.6068\n",
      "Epoch 892/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9295 - accuracy: 0.5726\n",
      "Epoch 893/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9176 - accuracy: 0.5983\n",
      "Epoch 894/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9397 - accuracy: 0.6154\n",
      "Epoch 895/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8835 - accuracy: 0.5641\n",
      "Epoch 896/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8540 - accuracy: 0.6068\n",
      "Epoch 897/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8962 - accuracy: 0.5897\n",
      "Epoch 898/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9240 - accuracy: 0.5470\n",
      "Epoch 899/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8641 - accuracy: 0.6410\n",
      "Epoch 900/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9664 - accuracy: 0.6068\n",
      "Epoch 901/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8931 - accuracy: 0.5470\n",
      "Epoch 902/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8961 - accuracy: 0.5983\n",
      "Epoch 903/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8950 - accuracy: 0.5812\n",
      "Epoch 904/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9556 - accuracy: 0.5128\n",
      "Epoch 905/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9175 - accuracy: 0.5726\n",
      "Epoch 906/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.9439 - accuracy: 0.5983\n",
      "Epoch 907/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9163 - accuracy: 0.5470\n",
      "Epoch 908/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9080 - accuracy: 0.5812\n",
      "Epoch 909/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8657 - accuracy: 0.5470\n",
      "Epoch 910/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8755 - accuracy: 0.6325\n",
      "Epoch 911/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8437 - accuracy: 0.6239\n",
      "Epoch 912/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8703 - accuracy: 0.5470\n",
      "Epoch 913/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8560 - accuracy: 0.5812\n",
      "Epoch 914/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9224 - accuracy: 0.5641\n",
      "Epoch 915/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9393 - accuracy: 0.5128\n",
      "Epoch 916/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8789 - accuracy: 0.6325\n",
      "Epoch 917/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8443 - accuracy: 0.5897\n",
      "Epoch 918/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9142 - accuracy: 0.5641\n",
      "Epoch 919/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8882 - accuracy: 0.5897\n",
      "Epoch 920/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8591 - accuracy: 0.6068\n",
      "Epoch 921/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8933 - accuracy: 0.5556\n",
      "Epoch 922/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8185 - accuracy: 0.6068\n",
      "Epoch 923/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9379 - accuracy: 0.5641\n",
      "Epoch 924/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9390 - accuracy: 0.5641\n",
      "Epoch 925/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9063 - accuracy: 0.5556\n",
      "Epoch 926/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9086 - accuracy: 0.5556\n",
      "Epoch 927/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9238 - accuracy: 0.5299\n",
      "Epoch 928/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9107 - accuracy: 0.5983\n",
      "Epoch 929/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8544 - accuracy: 0.6581\n",
      "Epoch 930/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8931 - accuracy: 0.5641\n",
      "Epoch 931/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9157 - accuracy: 0.5812\n",
      "Epoch 932/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9214 - accuracy: 0.5214\n",
      "Epoch 933/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9798 - accuracy: 0.5983\n",
      "Epoch 934/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 0s 111us/step - loss: 0.8977 - accuracy: 0.6410\n",
      "Epoch 935/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8612 - accuracy: 0.5726\n",
      "Epoch 936/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9211 - accuracy: 0.5983\n",
      "Epoch 937/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.8970 - accuracy: 0.6325\n",
      "Epoch 938/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8883 - accuracy: 0.6325\n",
      "Epoch 939/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9514 - accuracy: 0.5556\n",
      "Epoch 940/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8451 - accuracy: 0.6496\n",
      "Epoch 941/1000\n",
      "117/117 [==============================] - 0s 85us/step - loss: 0.9091 - accuracy: 0.6068\n",
      "Epoch 942/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8861 - accuracy: 0.5470\n",
      "Epoch 943/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8841 - accuracy: 0.5385\n",
      "Epoch 944/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8877 - accuracy: 0.6068\n",
      "Epoch 945/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9191 - accuracy: 0.5299\n",
      "Epoch 946/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9209 - accuracy: 0.6068\n",
      "Epoch 947/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8729 - accuracy: 0.5983\n",
      "Epoch 948/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8842 - accuracy: 0.5641\n",
      "Epoch 949/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9068 - accuracy: 0.5043\n",
      "Epoch 950/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8777 - accuracy: 0.6154\n",
      "Epoch 951/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8675 - accuracy: 0.5556\n",
      "Epoch 952/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8984 - accuracy: 0.5726\n",
      "Epoch 953/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8715 - accuracy: 0.5812\n",
      "Epoch 954/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8388 - accuracy: 0.6410\n",
      "Epoch 955/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9154 - accuracy: 0.5641\n",
      "Epoch 956/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8648 - accuracy: 0.6325\n",
      "Epoch 957/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9148 - accuracy: 0.5726\n",
      "Epoch 958/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9238 - accuracy: 0.6239\n",
      "Epoch 959/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9212 - accuracy: 0.5385\n",
      "Epoch 960/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8731 - accuracy: 0.6154\n",
      "Epoch 961/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8931 - accuracy: 0.6068\n",
      "Epoch 962/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8424 - accuracy: 0.5983\n",
      "Epoch 963/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9090 - accuracy: 0.6154\n",
      "Epoch 964/1000\n",
      "117/117 [==============================] - 0s 94us/step - loss: 0.8736 - accuracy: 0.5812\n",
      "Epoch 965/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8728 - accuracy: 0.5897\n",
      "Epoch 966/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8520 - accuracy: 0.5897\n",
      "Epoch 967/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8342 - accuracy: 0.5726\n",
      "Epoch 968/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8781 - accuracy: 0.5897\n",
      "Epoch 969/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.7892 - accuracy: 0.6923\n",
      "Epoch 970/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9017 - accuracy: 0.5897\n",
      "Epoch 971/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8975 - accuracy: 0.5214\n",
      "Epoch 972/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8711 - accuracy: 0.5556\n",
      "Epoch 973/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8370 - accuracy: 0.5726\n",
      "Epoch 974/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8777 - accuracy: 0.6239\n",
      "Epoch 975/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8979 - accuracy: 0.5983\n",
      "Epoch 976/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8157 - accuracy: 0.6154\n",
      "Epoch 977/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8945 - accuracy: 0.5726\n",
      "Epoch 978/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8751 - accuracy: 0.5812\n",
      "Epoch 979/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.7573 - accuracy: 0.7179\n",
      "Epoch 980/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8252 - accuracy: 0.6154\n",
      "Epoch 981/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9068 - accuracy: 0.6154\n",
      "Epoch 982/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8587 - accuracy: 0.5812\n",
      "Epoch 983/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8518 - accuracy: 0.5812\n",
      "Epoch 984/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9091 - accuracy: 0.6581\n",
      "Epoch 985/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.8586 - accuracy: 0.5897\n",
      "Epoch 986/1000\n",
      "117/117 [==============================] - 0s 77us/step - loss: 0.9366 - accuracy: 0.6154\n",
      "Epoch 987/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.9258 - accuracy: 0.5897\n",
      "Epoch 988/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8797 - accuracy: 0.5897\n",
      "Epoch 989/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8404 - accuracy: 0.5812\n",
      "Epoch 990/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8660 - accuracy: 0.6581\n",
      "Epoch 991/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.9083 - accuracy: 0.5983\n",
      "Epoch 992/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.8652 - accuracy: 0.6410\n",
      "Epoch 993/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8882 - accuracy: 0.6068\n",
      "Epoch 994/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8413 - accuracy: 0.5556\n",
      "Epoch 995/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8791 - accuracy: 0.5983\n",
      "Epoch 996/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8674 - accuracy: 0.5726\n",
      "Epoch 997/1000\n",
      "117/117 [==============================] - 0s 51us/step - loss: 0.9644 - accuracy: 0.5214\n",
      "Epoch 998/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8657 - accuracy: 0.6410\n",
      "Epoch 999/1000\n",
      "117/117 [==============================] - 0s 68us/step - loss: 0.8865 - accuracy: 0.5385\n",
      "Epoch 1000/1000\n",
      "117/117 [==============================] - 0s 60us/step - loss: 0.8676 - accuracy: 0.5556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x213d42d16d8>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras\n",
    "from keras.optimizers import SGD\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(124, input_dim=11, activation='relu'))  \n",
    "model3.add(Dropout(0.5))  # add dropout \n",
    "model3.add(Dense(124, input_dim=11, activation='relu')) \n",
    "model3.add(Dropout(0.5))  \n",
    "model3.add(Dense(124, activation='relu')) \n",
    "model3.add(Dropout(0.5))  \n",
    "\n",
    "model3.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model3.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 1000)  # increase epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_index=model3.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.626316</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.653636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.641026  0.626316   0.659091  0.653636    0     0    0   0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelevalobject3 = model_eval_metrics(y_test, predicted_labels, classification=\"TRUE\")\n",
    "modelevalobject3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Discuss which models performed better and point out relevant hyper-parameter values for successful models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model (model 3) performed best among all candidates. \n",
    "\n",
    "It is a neural network model with three hidden layers, each of which has 124 nodes. To prevent overfitting, I set dropout to 0.5, so every hidden unit is set to 0 with a probability of 0.5.\n",
    "\n",
    "I think the reason why it performed better than the other two models is because it uses dropout to deal with overfitting. Given we do not have many input data and the task is relatively simple, a complex model tend to suffer from overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Submit your best model to the leader board for the World Happiness AI Model Share competition.\n",
    "\n",
    "You have the option to discuss these models in your report, but it is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I submitted the best model to AI Model Share competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('mymodel.onnx'):\n",
    "    from keras2onnx import convert_keras\n",
    "    onx = convert_keras(model3, 'mymodel.onnx')\n",
    "    with open(\"mymodel.onnx\", \"wb\") as f:\n",
    "        f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading AWS keys necessary to submit model.  Loading to object, so we don't print them out in our notebook\n",
    "aws_key_password_region = pickle.load(open( \"data/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Model Pre-launched into Model Share Site\n",
    "apiurl=\"https://btuvanmi55.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "username = # removed when commit to github\n",
    "password = # removed when commit to github\n",
    "\n",
    "\n",
    "region='us-east-1'\n",
    "model_filepath=\"mymodel.onnx\"   \n",
    "preprocessor_filepath=\"preprocessor.pkl\"\n",
    "preprocessor=\"TRUE\"\n",
    "\n",
    "trainingdata=X_train\n",
    "\n",
    "# Set aws keys for this project (these keys give you access to collaborate on a single project)\n",
    "\n",
    "#Importing from object that stores keys so we do not print out keys for others to see.\n",
    "\n",
    "aws_key_password_region = pickle.load( open( \"data/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) )\n",
    "\n",
    "aws_key=aws_key_password_region[0]\n",
    "aws_password=aws_key_password_region[1]\n",
    "region=aws_key_password_region[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"mymodel.onnx\" has been loaded to version 83 of your prediction API.\n",
      "This version of the model will be used by your prediction api for all future predictions automatically.\n",
      "If you wish to use an older version of the model, please reference the getting started guide at aimodelshare.com.\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.submit_model(model_filepath=model_filepath, model_eval_metrics=modelevalobject3,apiurl=apiurl, username=username, password=password, aws_key=aws_key,aws_password=aws_password, region=region, trainingdata=trainingdata,preprocessor_filepath=preprocessor_filepath,preprocessor=preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEADERBOARD RANKINGS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>username</th>\n",
       "      <th>model_version</th>\n",
       "      <th>avg_ranking_classification</th>\n",
       "      <th>avg_ranking_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>70</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675975</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>69</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>62</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.642381</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>83</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.646886</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>68</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.639160</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>81</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.639160</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>82</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.620793</td>\n",
       "      <td>0.634394</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>79</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.594805</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>67</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.620793</td>\n",
       "      <td>0.634394</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>80</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.625909</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>19</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.604242</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>37</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.516576</td>\n",
       "      <td>0.594383</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>77</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482925</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bavilaa</td>\n",
       "      <td>20</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482925</td>\n",
       "      <td>0.605195</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bavilaa</td>\n",
       "      <td>21</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.481021</td>\n",
       "      <td>0.595671</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>54</td>\n",
       "      <td>12.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>43</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>63</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>49</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>59</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yaowang126</td>\n",
       "      <td>46</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>26</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>24</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>64</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>65</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>66</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>15</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>22</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.482559</td>\n",
       "      <td>0.576623</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sding</td>\n",
       "      <td>51</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.490872</td>\n",
       "      <td>0.543651</td>\n",
       "      <td>0.531429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>72</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.419679</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ccabelloe</td>\n",
       "      <td>52</td>\n",
       "      <td>24.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.411048</td>\n",
       "      <td>0.437143</td>\n",
       "      <td>0.451429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>71</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>61</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>7</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>9</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>12</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>39</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>35</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>11</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>42</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>33</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>29</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>28</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>8</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>53</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nayyer-Qureshi</td>\n",
       "      <td>28</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>44</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>34</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>38</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>60</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>10</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>31</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XU</td>\n",
       "      <td>32</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>30</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ccabelloe</td>\n",
       "      <td>36</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.343861</td>\n",
       "      <td>0.348889</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>50</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.303896</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>18</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>6</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>2</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>3</td>\n",
       "      <td>28.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  f1_score  precision    recall  mse  rmse  mae  r2  \\\n",
       "37  0.717949  0.713796   0.719444  0.725000    0     0    0   0   \n",
       "78  0.666667  0.675975   0.754286  0.700952    0     0    0   0   \n",
       "38  0.692308  0.693333   0.700397  0.702778    0     0    0   0   \n",
       "61  0.641026  0.642381   0.743590  0.682273    0     0    0   0   \n",
       "47  0.641026  0.646886   0.738333  0.680952    0     0    0   0   \n",
       "18  0.641026  0.639160   0.660476  0.700455    0     0    0   0   \n",
       "52  0.641026  0.639160   0.660476  0.700455    0     0    0   0   \n",
       "51  0.615385  0.620793   0.634394  0.658636    0     0    0   0   \n",
       "10  0.589744  0.594805   0.714286  0.640952    0     0    0   0   \n",
       "16  0.615385  0.620793   0.634394  0.658636    0     0    0   0   \n",
       "13  0.512821  0.508060   0.625909  0.544444    0     0    0   0   \n",
       "42  0.512821  0.504464   0.604242  0.544444    0     0    0   0   \n",
       "25  0.512821  0.516576   0.594383  0.530556    0     0    0   0   \n",
       "23  0.487179  0.482925   0.605195  0.511111    0     0    0   0   \n",
       "33  0.487179  0.482925   0.605195  0.511111    0     0    0   0   \n",
       "75  0.487179  0.481021   0.595671  0.511111    0     0    0   0   \n",
       "15  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "55  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "56  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "8   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "43  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "60  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "39  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "22  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "62  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "2   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "1   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "35  0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "0   0.487179  0.482559   0.576623  0.511111    0     0    0   0   \n",
       "82  0.487179  0.490872   0.543651  0.531429    0     0    0   0   \n",
       "..       ...       ...        ...       ...  ...   ...  ...  ..   \n",
       "21  0.410256  0.419679   0.503571  0.425000    0     0    0   0   \n",
       "29  0.410256  0.411048   0.437143  0.451429    0     0    0   0   \n",
       "70  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "76  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "66  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "65  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "63  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "73  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "30  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "9   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "58  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "31  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "28  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "34  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "27  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "26  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "20  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "59  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "44  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "49  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "12  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "54  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "57  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "45  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "41  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "77  0.384615  0.343861   0.348889  0.422222    0     0    0   0   \n",
       "11  0.384615  0.303896   0.340260  0.425000    0     0    0   0   \n",
       "17  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "69  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "3   0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "\n",
       "          username  model_version  avg_ranking_classification  \\\n",
       "37          3scman             70                    2.000000   \n",
       "78       dhoward97             69                    2.333333   \n",
       "38          3scman             62                    3.333333   \n",
       "61      SUN-Wenjun             83                    3.666667   \n",
       "47       dhoward97             68                    3.666667   \n",
       "18      SUN-Wenjun             81                    5.666667   \n",
       "52      SUN-Wenjun             82                    5.666667   \n",
       "51      SUN-Wenjun             79                    6.666667   \n",
       "10       dhoward97             67                    6.333333   \n",
       "16      SUN-Wenjun             80                    6.666667   \n",
       "13      Yihui_Wang             19                    9.333333   \n",
       "42   Paarth_Malkan             37                   10.333333   \n",
       "25          Taketo             77                   10.000000   \n",
       "23         bavilaa             20                   11.333333   \n",
       "33         bavilaa             21                   11.333333   \n",
       "75      SUN-Wenjun             54                   12.666667   \n",
       "15          Taketo             43                   13.000000   \n",
       "55       dhoward97             63                   13.000000   \n",
       "56    seanmcalevey             49                   13.000000   \n",
       "8           3scman             59                   13.000000   \n",
       "43      yaowang126             46                   13.000000   \n",
       "60          Taketo             26                   13.000000   \n",
       "39         AlisaAi             24                   13.000000   \n",
       "22       dhoward97             64                   13.000000   \n",
       "62       dhoward97             65                   13.000000   \n",
       "2        dhoward97             66                   13.000000   \n",
       "1          zivzach             15                   13.000000   \n",
       "35          jaeham             22                   13.000000   \n",
       "0            sding             51                   13.000000   \n",
       "82         AlisaAi             72                   14.333333   \n",
       "..             ...            ...                         ...   \n",
       "21       ccabelloe             52                   24.333333   \n",
       "29      SUN-Wenjun             71                   26.000000   \n",
       "70       dhoward97             61                   26.333333   \n",
       "76       username2              7                   26.333333   \n",
       "66       username2              9                   26.333333   \n",
       "65       username2             12                   26.333333   \n",
       "63         AlisaAi             39                   26.333333   \n",
       "73          jaeham             35                   26.333333   \n",
       "30       username2             11                   26.333333   \n",
       "9    Paarth_Malkan             42                   26.333333   \n",
       "58          3scman             33                   26.333333   \n",
       "31    seanmcalevey             29                   26.333333   \n",
       "28      SUN-Wenjun             28                   26.333333   \n",
       "34       username2              8                   26.333333   \n",
       "27   Paarth_Malkan             53                   26.333333   \n",
       "26  Nayyer-Qureshi             28                   26.333333   \n",
       "20   Paarth_Malkan             44                   26.333333   \n",
       "59          Taketo             34                   26.333333   \n",
       "44      Yihui_Wang             38                   26.333333   \n",
       "49    seanmcalevey             60                   26.333333   \n",
       "12       username2             10                   26.333333   \n",
       "54        abhay_07             31                   26.333333   \n",
       "57              XU             32                   26.333333   \n",
       "45         zivzach             30                   26.333333   \n",
       "41       ccabelloe             36                   26.333333   \n",
       "77         zivzach             50                   28.000000   \n",
       "11        abhay_07             18                   29.000000   \n",
       "17       username2              6                   28.333333   \n",
       "69       username2              2                   28.333333   \n",
       "3        username2              3                   28.333333   \n",
       "\n",
       "    avg_ranking_regression  \n",
       "37                     1.0  \n",
       "78                     1.0  \n",
       "38                     1.0  \n",
       "61                     1.0  \n",
       "47                     1.0  \n",
       "18                     1.0  \n",
       "52                     1.0  \n",
       "51                     1.0  \n",
       "10                     1.0  \n",
       "16                     1.0  \n",
       "13                     1.0  \n",
       "42                     1.0  \n",
       "25                     1.0  \n",
       "23                     1.0  \n",
       "33                     1.0  \n",
       "75                     1.0  \n",
       "15                     1.0  \n",
       "55                     1.0  \n",
       "56                     1.0  \n",
       "8                      1.0  \n",
       "43                     1.0  \n",
       "60                     1.0  \n",
       "39                     1.0  \n",
       "22                     1.0  \n",
       "62                     1.0  \n",
       "2                      1.0  \n",
       "1                      1.0  \n",
       "35                     1.0  \n",
       "0                      1.0  \n",
       "82                     1.0  \n",
       "..                     ...  \n",
       "21                     1.0  \n",
       "29                     1.0  \n",
       "70                     1.0  \n",
       "76                     1.0  \n",
       "66                     1.0  \n",
       "65                     1.0  \n",
       "63                     1.0  \n",
       "73                     1.0  \n",
       "30                     1.0  \n",
       "9                      1.0  \n",
       "58                     1.0  \n",
       "31                     1.0  \n",
       "28                     1.0  \n",
       "34                     1.0  \n",
       "27                     1.0  \n",
       "26                     1.0  \n",
       "20                     1.0  \n",
       "59                     1.0  \n",
       "44                     1.0  \n",
       "49                     1.0  \n",
       "12                     1.0  \n",
       "54                     1.0  \n",
       "57                     1.0  \n",
       "45                     1.0  \n",
       "41                     1.0  \n",
       "77                     1.0  \n",
       "11                     1.0  \n",
       "17                     1.0  \n",
       "69                     1.0  \n",
       "3                      1.0  \n",
       "\n",
       "[83 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "leaderboard = ai.get_leaderboard(apiurl, username, password, aws_key, aws_password, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
